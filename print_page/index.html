
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://soilwise-he.github.io/SoilWise-documentation/print_page/">
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Printable version - Living Technical Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/print-site-enum-headings1.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings2.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings3.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings4.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings5.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings6.css">
    
      <link rel="stylesheet" href="../css/print-site.css">
    
      <link rel="stylesheet" href="../css/print-site-material.css">
    
      <link rel="stylesheet" href="../extra.css">
    
      <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    
    <script>__md_scope=new URL("/SoilWise-documentation/",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  
        <script type="text/javascript">
        document.addEventListener('DOMContentLoaded', function () {
            remove_material_navigation();remove_mkdocs_theme_navigation();generate_toc();
        })
        </script>
        </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="brown" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Living Technical Documentation" class="md-header__button md-logo" aria-label="Living Technical Documentation" data-md-component="logo">
      
  <img src="../_assets/images/SoilWise_logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Living Technical Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Printable version
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="brown" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="brown"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/soilwise-he/SoilWise-documentation" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../technical_components/technical_components/" class="md-tabs__link">
          
  
    
  
  Technical Components

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../apis/apis-intro/" class="md-tabs__link">
          
  
    
  
  APIs

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../infrastructure/infrastructure-intro/" class="md-tabs__link">
          
  
    
  
  Infrastructure

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../glossary/" class="md-tabs__link">
        
  
    
  
  Glossary

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="./" class="md-tabs__link">
        
  
    
  
  Printable version

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Living Technical Documentation" class="md-nav__button md-logo" aria-label="Living Technical Documentation" data-md-component="logo">
      
  <img src="../_assets/images/SoilWise_logo.png" alt="logo">

    </a>
    Living Technical Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/soilwise-he/SoilWise-documentation" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Technical Components
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Technical Components
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/technical_components/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/ingestion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Harvester
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Repository Storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/catalogue/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Catalogue
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/metadata_validation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metadata Validation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/metadata_authoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metadata Authoring
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/transformation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformation and Harmonisation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/metadata_augmentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metadata Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/knowledge_graph/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Graph
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/natural_language_querying/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Natural Language Querying
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical_components/user_management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    User Management and Access Control
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    APIs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apis/apis-intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Infrastructure
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Infrastructure
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infrastructure/infrastructure-intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infrastructure/containerization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Containerization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infrastructure/git/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GIT versioning system
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Printable version
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Printable version
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#" class="md-nav__link">
    <span class="md-ellipsis">
      1. Home
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-technical-components" class="md-nav__link">
    <span class="md-ellipsis">
      I. Technical Components
    </span>
  </a>
  
    <nav class="md-nav" aria-label="I. Technical Components">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#technical_components-technical_components" class="md-nav__link">
    <span class="md-ellipsis">
      2. Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-ingestion" class="md-nav__link">
    <span class="md-ellipsis">
      3. Harvester
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-storage" class="md-nav__link">
    <span class="md-ellipsis">
      4. Repository Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-catalogue" class="md-nav__link">
    <span class="md-ellipsis">
      5. Catalogue
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-metadata_validation" class="md-nav__link">
    <span class="md-ellipsis">
      6. Metadata Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-metadata_authoring" class="md-nav__link">
    <span class="md-ellipsis">
      7. Metadata Authoring
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-transformation" class="md-nav__link">
    <span class="md-ellipsis">
      8. Transformation and Harmonisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-metadata_augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      9. Metadata Augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-knowledge_graph" class="md-nav__link">
    <span class="md-ellipsis">
      10. Knowledge Graph
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-natural_language_querying" class="md-nav__link">
    <span class="md-ellipsis">
      11. Natural Language Querying
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-user_management" class="md-nav__link">
    <span class="md-ellipsis">
      12. User Management and Access Control
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-apis" class="md-nav__link">
    <span class="md-ellipsis">
      II. APIs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="II. APIs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apis-apis-intro" class="md-nav__link">
    <span class="md-ellipsis">
      13. Introduction
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-infrastructure" class="md-nav__link">
    <span class="md-ellipsis">
      III. Infrastructure
    </span>
  </a>
  
    <nav class="md-nav" aria-label="III. Infrastructure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#infrastructure-infrastructure-intro" class="md-nav__link">
    <span class="md-ellipsis">
      14. Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infrastructure-containerization" class="md-nav__link">
    <span class="md-ellipsis">
      15. Containerization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infrastructure-git" class="md-nav__link">
    <span class="md-ellipsis">
      16. GIT versioning system
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#glossary" class="md-nav__link">
    <span class="md-ellipsis">
      17. Glossary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#" class="md-nav__link">
    <span class="md-ellipsis">
      1. Home
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-technical-components" class="md-nav__link">
    <span class="md-ellipsis">
      I. Technical Components
    </span>
  </a>
  
    <nav class="md-nav" aria-label="I. Technical Components">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#technical_components-technical_components" class="md-nav__link">
    <span class="md-ellipsis">
      2. Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-ingestion" class="md-nav__link">
    <span class="md-ellipsis">
      3. Harvester
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-storage" class="md-nav__link">
    <span class="md-ellipsis">
      4. Repository Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-catalogue" class="md-nav__link">
    <span class="md-ellipsis">
      5. Catalogue
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-metadata_validation" class="md-nav__link">
    <span class="md-ellipsis">
      6. Metadata Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-metadata_authoring" class="md-nav__link">
    <span class="md-ellipsis">
      7. Metadata Authoring
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-transformation" class="md-nav__link">
    <span class="md-ellipsis">
      8. Transformation and Harmonisation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-metadata_augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      9. Metadata Augmentation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-knowledge_graph" class="md-nav__link">
    <span class="md-ellipsis">
      10. Knowledge Graph
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-natural_language_querying" class="md-nav__link">
    <span class="md-ellipsis">
      11. Natural Language Querying
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical_components-user_management" class="md-nav__link">
    <span class="md-ellipsis">
      12. User Management and Access Control
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-apis" class="md-nav__link">
    <span class="md-ellipsis">
      II. APIs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="II. APIs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apis-apis-intro" class="md-nav__link">
    <span class="md-ellipsis">
      13. Introduction
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-infrastructure" class="md-nav__link">
    <span class="md-ellipsis">
      III. Infrastructure
    </span>
  </a>
  
    <nav class="md-nav" aria-label="III. Infrastructure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#infrastructure-infrastructure-intro" class="md-nav__link">
    <span class="md-ellipsis">
      14. Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infrastructure-containerization" class="md-nav__link">
    <span class="md-ellipsis">
      15. Containerization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infrastructure-git" class="md-nav__link">
    <span class="md-ellipsis">
      16. GIT versioning system
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#glossary" class="md-nav__link">
    <span class="md-ellipsis">
      17. Glossary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<div id="print-site-page" class="print-site-enumerate-headings print-site-enumerate-figures">
        <section class="print-page">
            <div id="print-page-toc" data-toc-depth="3">
                <nav role='navigation' class='print-page-toc-nav'>
                <h1 class='print-page-toc-title'>Table of Contents</h1>
                </nav>
            </div>
        </section>
        <section class="print-page" id="index"><h1 id="index-welcome-to-the-soilwise-technical-documentation">Welcome to the SoilWise Technical Documentation!</h1>
<p>SoilWise Technical Documentation currently consists of the following sections:</p>
<ol>
<li><a href="#technical_components-technical_components">Technical Components</a></li>
<li><a href="#apis-apis-intro">APIs</a></li>
<li><a href="#infrastructure-infrastructure-intro">Infrastructure</a></li>
<li><a href="#glossary">Glossary</a></li>
<li><a href="#print_page">Printable version</a> - where you find all sections composed in one page, that can be easily printed using Web Browser options</li>
</ol>
<h2 id="index-essential-terminology">Essential Terminology</h2>
<p>A full list of terms used within this Technical Documentation can be found in the <a href="#glossary">Glossary</a>. The most essential ones are defined as follows:</p>
<ul>
<li><strong>(Descriptive) metadata:</strong>  Summary information describing digital objects such as datasets and knowledge resources.</li>
<li>
<p><strong>Metadata record:</strong> An entry in e.g. a catalogue or abstracting and indexing service with summary information about a digital object.</p>
</li>
<li>
<p><strong>Data:</strong> A collection of discrete or continuous values that convey information, describing the quantity, quality, fact, statistics, other basic units of meaning, or simply sequences of symbols that may be further interpreted formally (<a href="https://en.wikipedia.org/wiki/Data">Wikipedia</a>).</p>
</li>
<li>
<p><strong>Dataset:</strong> (Also: Data set) A collection of data (<a href="https://en.wikipedia.org/wiki/Data_set">Wikipedia</a>).</p>
</li>
<li>
<p><strong>Knowledge:</strong>  Facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject. SoilWise mainly considers <em>explicit knowledge</em> -- Information that is easily articulated, codified, stored, and accessed. E.g. via books, web sites, or databases. It does not include <em>implicit knowledge</em> (information transferable via skills) nor <em>tacit knowledge</em> (gained via personal experiences and individual contexts). Explicit knowledge can be further divided into semantic and structural knowledge:</p>
<ul>
<li><strong>Semantic knowledge:</strong> Also known as declarative knowledge, refers to knowledge about facts, meanings, concepts, and relationships. It is the understanding of the world around us, conveyed through language. Semantic knowledge answers the <em>"What?"</em> question about facts and concepts.</li>
<li><strong>Structural knowledge:</strong> Knowledge about the organisation and interrelationships among pieces of information. It is about understanding how different pieces of information are interconnected. Structural knowledge explains the <em>"How?" and "Why?"</em> regarding the organisation and relationships among facts and concepts.</li>
</ul>
</li>
<li><strong>Knowledge resource:</strong> A digital object, such as a document, a web page, or a database, that holds relevant <em>explicit knowledge</em>.</li>
</ul>
<h2 id="index-release-notes">Release notes</h2>
<table>
<thead>
<tr>
<th>Date</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td>30. 9. 2024</td>
<td><strong>v2.0 Released:</strong> For <em>D2.1 Developed &amp; Integrated DM components, v1 D3.1 Developed &amp; Integrated KM components, v1</em> and <em>D4.1 Repository infrastructure, components and APIs, v1</em> purposes</td>
</tr>
<tr>
<td>30. 9. 2024</td>
<td>Technical Components functionality updated according to first SoilWise repository prototype</td>
</tr>
<tr>
<td>27. 8. 2024</td>
<td>APIs section restructured</td>
</tr>
<tr>
<td>20. 8. 2024</td>
<td>Knowledge Graph component added</td>
</tr>
<tr>
<td>13. 8. 2024</td>
<td>Metadata Authoring component added</td>
</tr>
<tr>
<td>1. 7. 2024</td>
<td>Metadata Augmentation component added</td>
</tr>
<tr>
<td>30. 4. 2024</td>
<td><strong>v1.0 Released:</strong> For <em>D1.3 Architecture Repository v1</em> purposes</td>
</tr>
<tr>
<td>27. 3. 2024</td>
<td>Technical Components restructured according to the architecture from Brugges Technical Meeting</td>
</tr>
<tr>
<td>27. 3. 2024</td>
<td><strong>v0.1 Released:</strong> Technical documentation based on the Consolidated architecture</td>
</tr>
<tr>
<td>10. 2. 2024</td>
<td>Technical Documentation was initialized</td>
</tr>
</tbody>
</table></section>
                        <h1 class='nav-section-title' id='section-technical-components'>
                            Technical Components <a class='headerlink' href='#section-technical-components' title='Permanent link'>↵</a>
                        </h1>
                        <section class="print-page" id="technical_components-technical_components"><h1 id="technical_components-technical_components-introduction">Introduction</h1>
<p>The SoilWise Repository (SWR) architecture aims towards efficient facilitation of soil data management. It seamlessly gathers, processes, and disseminates data from diverse sources. The system prioritizes high-quality data dissemination, knowledge extraction and interoperability while user management and monitoring tools ensure secure access and system health. Note that, SWR primarily serves to power Decision Support Systems (DSS) rather than being a DSS itself.</p>
<p>The presented architecture represents an outlook and a framework for ongoing SoilWise development. As such, the implementation has been following intrinsic (within the SoilWise project) and extrinsic (e.g. EUSO development Mission Soil Projects) opportunities and limitations. The presented architecture is the first release out of two planned. Modifications during the implementation will be incorporated into the final version of the SoilWise architecture due M42.</p>
<p>This section lists technical components for building the SoilWise Repository as forseen in the architecture design. As for now, the following components are foreseen:</p>
<ol>
<li><a href="#technical_components-ingestion">Harvester</a></li>
<li><a href="#technical_components-storage">Repository Storage</a></li>
<li><a href="#technical_components-catalogue">Catalogue</a></li>
<li><a href="#technical_components-metadata_validation">Metadata Validation</a></li>
<li><a href="#technical_components-metadata_authoring">Metadata Authoring</a></li>
<li><a href="#technical_components-transformation">Transformation and Harmonistation</a></li>
<li><a href="#technical_components-metadata_augmentation">Metadata Augmentation</a></li>
<li><a href="#technical_components-knowledge_graph">Knowledge Graph</a></li>
<li><a href="#technical_components-natural_language_querying">Natural Language Querying</a></li>
<li><a href="#technical_components-user_management">User Management and Access Control</a></li>
</ol>
<iframe style="width:100%; height:800px"src="https://prototype-1-0.soilwise-architecture.pages.dev/?view=id-e3ae52bba4fb42dfa0b3900e7d3"></iframe>

<p>A full version of architecture diagram is available at: <a href="https://soilwise-he.github.io/soilwise-architecture/" target="_blank">https://soilwise-he.github.io/soilwise-architecture/</a>.</p></section><section class="print-page" id="technical_components-ingestion"><h1 id="technical_components-ingestion-harvester">Harvester</h1>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 0.1.0</p>
<p><strong>Project:</strong> <a href="https://github.com/soilwise-he/harvesters">Harvesters</a></p>
</div>
<p>The Harvester component is dedicated to automatically harvest sources to populate SWR with metadata on <a href="#technical_components-ingestion-datasets">datasets</a> and <a href="#technical_components-ingestion-knowledge-sources">knowledge sources</a>.</p>
<h2 id="technical_components-ingestion-metadata-harvesting-concept">Metadata harvesting concept</h2>
<p>Metadata harvesting is the process of ingesting metadata, i.e. evidence on data and knowledge, from remote sources and storing it locally in the catalogue for fast searching. It is a scheduled process, so local copy and remote metadata are kept aligned. Various components exist which are able to harvest metadata from various (standardised) API's. SoilWise aims to use existing components where available.</p>
<p>The harvesting mechanism relies on the concept of a <em>universally unique identifier (UUID)</em> or <em>unique resource identifier (URI)</em> that is being assigned commonly by metadata creator or publisher. Another important concept behind the harvesting is the <em>last change date</em>. Every time a metadata record is changed, the last change date is updated. Just storing this parameter and comparing it with a new one allows any system to find out if the metadata record has been modified since last update. An exception is if metadata is removed remotely. SoilWise Repository can only derive that fact by harvesting the full remote content. Discussion is needed to understand if SWR should keep a copy of the remote source anyway, for archiving purposes. All metadata with an update date newer then <em>last-identified successfull harvester run</em> are extracted from remote location. </p>
<p>A harvesting task typically extracts records with update-date later then the <em>last-identified successfull harvester run</em>.</p>
<p>Harvested content is (by default) not editable for the following reasons:</p>
<ol>
<li>The harvesting is periodic so any local change to harvested metadata will be lost during the next run.</li>
<li>The change date may be used to keep track of changes so if the metadata gets changed, the harvesting mechanism may be compromised.</li>
</ol>
<p>If inconsistencies with imported metadata are identified, we can add a statement to the graph of such inconsistencies. We can also notify the author of the inconsistency so they can fix the inconsistency on their side.</p>
<p>A governance aspect still under discussion is if harvested content is removed as soon as a harvester configuration is removed, or when records are removed from the remote endpoint. The risk of removing content is that relations within the graph are breached. An alternative is to indicate the record has been archived by the provider.</p>
<p>Typical tasks of a harvester:</p>
<ul>
<li><strong>Define a harvester job</strong><ul>
<li>Schedule (on request, weekly, daily, hourly)</li>
<li>Endpoint / Endpoint type (example.com/csw -&gt; OGC:CSW)</li>
<li>Apply a filter (only records with keyword='soil-mission')</li>
</ul>
</li>
<li><strong>Understand success of a harvest job</strong> <ul>
<li>overview of harvested content (120 records)</li>
<li>which runs failed, why? (today failed -&gt; log, yesterday successfull -&gt; log)</li>
<li>Monitor running harvestors (20% done -&gt; cancel)</li>
</ul>
</li>
<li><strong>Define behaviours on harvested content</strong><ul>
<li>skip records with low quality (if test xxx fails)</li>
<li>mint identifier if missing ( https://example.com/data/{uuid} )</li>
<li>a model transformation before ingestion ( example-transform.xsl / do-something.py )</li>
</ul>
</li>
</ul>
<h2 id="technical_components-ingestion-resource-types">Resource Types</h2>
<p>Metadata for following resource types are foreseen to be harvested:</p>
<ul>
<li>Data &amp; Knowledge Resources </li>
<li>Organisations, Projects, LTE, Living labs initiatives</li>
<li>Repositories/Catalogues</li>
</ul>
<p>These entities relate to each other as:</p>
<pre  class="mermaid"><code>flowchart LR
    people -->|memberOf| o[organisations] 
    o -->|partnerIn| p[projects]
    p -->|produce| d[data & knowledge resources]
    o -->|publish| d
    d -->|describedIn| c[catalogues]
    p -->|part-of| fs[Fundingscheme]
</code></pre>
<h3 id="technical_components-ingestion-datasets">Datasets</h3>
<p>Metadata records of datasets are, for the first iteration, primarily imported from the <strong>ESDAC</strong>, <strong>INSPIRE GeoPortal</strong>, <strong>BonaRes</strong> and <strong>Cordis</strong>/<strong>OpenAire</strong>. In later iterations SoilWise aims to include other projects and portals, such as <strong>national</strong> or <strong>thematic portals</strong>. These repositories contain large number of datasets. Selection of key datasets concerning the SoilWise scope is a subject of know-how to be developed within SoilWise.</p>
<h3 id="technical_components-ingestion-knowledge-sources">Knowledge sources</h3>
<p>With respect to harvesting, it is important to note that knowledge assets are heterogeneous, and that (compared to data), metadata standards and particularly access / harvesting protocols are not generally adopted. Available metadata might be implemented using a proprietary schema, and basic assumptions for harvesting, e.g. providing a "date of last change" might not be offered. This will, in some cases, make it necessary to develop customized harvesting and metadata extraction processes. It also means that informed decisions need to be made on which resources to include, based on priority, required efforts and available capacity.</p>
<p>The SoilWise project team is still exploring which knowledge resources to include. As an example, an important cluster of knowledge sources may be seen academic articles and report deliverables from Mission Soil Horizon Europe projects. These resources are accessible from <strong>ESDAC</strong>, <strong>Cordis</strong> and <strong>OpenAire</strong>. Extracting content from Cordis, OpenAire can be achieved using a harvesting task (using the Cordis schema, extended with post processing). For the first iteration, SoilWise aims to achieve this goal. In future iterations new knowledge sources may become relevant, we will investigate at that moment what is the best approach to harvest them.</p>
<h2 id="technical_components-ingestion-functionality">Functionality</h2>
<p>The Harvester component currently comprises of the following functions:</p>
<ul>
<li><a href="#technical_components-ingestion-harvest-records-from-metadata-and-knowledge-resources">Harvest records from metadata and knowledge resources</a></li>
<li><a href="#technical_components-ingestion-metadata-harmonization">Metadata harmonization</a></li>
<li><a href="#technical_components-ingestion-metadata-rdf-turtle-serialization">Metadata RDF turtle serialization</a></li>
<li><a href="#technical_components-ingestion-rdf-to-triple-store">RDF to Triple Store</a></li>
<li><a href="#technical_components-ingestion-duplication-indentification">Duplication identification</a></li>
</ul>
<h3 id="technical_components-ingestion-harvest-records-from-metadata-and-knowledge-resources">Harvest records from metadata and knowledge resources</h3>
<p>Note, the first SoilWise Repository development iteration resulted in <strong>9,0444</strong> harvested metadata records (to date 12.09.20241).</p>
<h4 id="technical_components-ingestion-cordis">CORDIS</h4>
<p>European Research projects typically advertise their research outputs via <a href="https://cordis.europa.eu/" target="_blank">Cordis</a>. This makes Cordis a likely candidate to discover research outputs, such as reports, articles and datasets. Cordis does not capture many metadata properties. In those cases where a resource is identified by a <a href="https://www.doi.org/the-identifier/what-is-a-doi/" target="_blank">DOI</a>, additional metadata can be found in OpenAire via the DOI. The scope of projects, from which to include project deliverables is still under discussion. </p>
<p>Which projects to include is derived from 2 sources:</p>
<ul>
<li><a href="https://esdac.jrc.ec.europa.eu/projects/Eufunded/Eufunded.html" target="_blank">ESDAC</a> maintains a list of historic EU funded research projects</li>
<li><a href="https://mission-soil-platform.ec.europa.eu/project-hub/funded-projects-under-mission-soil" target="_blank">Mission soil platform</a> maintains a list of current Mission soil projects</li>
</ul>
<p>A script fetches the content from these 2 sources and prepares for the CORDIS and OpenAire harvested to understand which content is relevant. The content in these pages is unstructured html. The content is scraped using a python library. This is not optimal, because the scraper expects a dedicated html structure, which is fragile.</p>
<p>Results of the scrape activity are stored in table <code>harvest.projects</code>. For each project a Record control number(<a href="https://www.wikidata.org/wiki/Property:P5755" target="_blank">RCN</a>) is retrieved from the Cordis knowledge graph. This RCN could be used to filter OpenAire, however OpenAire can also be filtered using project grant number. At this moment in time the Cordis Knowledge graph does not contain the Mission Soil projects yet. </p>
<p>At this moment in time we do not harvest resources from Cordis which do not have a DOI. This includes mainly progress reports of the projects. </p>
<h4 id="technical_components-ingestion-openaire">OpenAire</h4>
<p>For those resources, discovered via Cordis/ESDAC, and identified by a DOI, a harvester fetches additional metadata from OpenAire. OpenAire is a catalogue initiative which harvests metadata from popular scientific repositories, such as Zenodo, Dataverse, etc.</p>
<p>Not all DOI's registered in Cordis are available in OpenAire. OpenAire only lists resources with an open access license. Other DOI's can be fetched from the DOI registry directly or via Crossref.org. This work is still in preparation.</p>
<p>Records in OpenAire are stored in the Open Aire Research Graph (<a href="https://www.openaire.eu/schema/1.0/doc/oaf-1.0.html" target="_blank">OAF</a>) format, which is transformed to a metadata set based on Dublin Core.</p>
<h4 id="technical_components-ingestion-ogc-csw">OGC-CSW</h4>
<p>Many (spatial) catalogues advertise their metadata via the <a href="https://www.ogc.org/standard/cat/" target="_blank">catalogue Service for the Web</a> standard, such as INSPIRE GeoPortal, Bonares, ISRIC. The <a href="https://github.com/geopython/owslib" target="_blank">OWSLib</a> library is used to query records from CSW endpoints. A filter can be configured to retrieve subsets of the catalogue.</p>
<p>Incidentally, records advertised as CSW also include a DOI reference (Bonares/ISRIC). Additional metadata for these DOI's is extracted from OpenAire/Crossref.</p>
<h4 id="technical_components-ingestion-inspire">INSPIRE</h4>
<p>Although <a href="https://inspire-geoportal.ec.europa.eu/" target="_blank">INSPIRE Geoportal</a> does offer a CSW endpoint, due to a technical reasons, we have not been able to harvest from it. Instead we have developed a dedicated harvester via the Elastic Search API endpoint of the Geoportal. If at some point the technical issue has been resolved, use of the CSW harvest endpoint is favourable.</p>
<h4 id="technical_components-ingestion-esdac">ESDAC</h4>
<p>The <a href="https://esdac.jrc.ec.europa.eu/" target="_blank">ESDAC catalogue</a> is an instance of Drupal CMS. We have developed a dedicated harvester to scrape html elements to extract Dublin Core metadata from ESDAC html elements. Metadata is extracted for datasets, maps (EUDASM) and documents. Incidentally a DOI is mentioned as part of the HTML, this DOI is then used as identifier for the resource, else the resource url is used as identifier. If the DOI is not known to the system yet, OpenAire will be queried to capture additional metadata on the resource.</p>
<h4 id="technical_components-ingestion-impact4soil">Impact4Soil</h4>
<p>Impact4soil is build on a Strapi.io headless CMS. The CMS provides an API to retrieve datasets and scientific articles. The API provides minimal metadata, but fortunately in most cases a DOI is included. DOI is used to capture additional metadata from OpenAire.</p>
<h4 id="technical_components-ingestion-prepsoil-portal">Prepsoil portal</h4>
<p>Prep4soil is build on a headless CMS. The CMS at times provides an API to retrieve datasets, knowledge items, living labs, lighthouses and communities of practice. The API provides minimal metadata, incidentally a DOI is included. DOI is used to capture additional metadata from OpenAire.</p>
<h3 id="technical_components-ingestion-metadata-harmonization">Metadata Harmonization</h3>
<p>Once stored in the harvest sources database, a second process is triggered which harmonizes the sources to the desired metadata profile. These processes are split by design, to prevent that any failure in metadata processing would require to fetch remote content again.</p>
<p>Table below indicates the various source models supported</p>
<table>
<thead>
<tr>
<th>source</th>
<th>platform</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dublin Core</td>
<td>Cordis</td>
</tr>
<tr>
<td>Extended Dublin core</td>
<td>ESDAC</td>
</tr>
<tr>
<td>Datacite</td>
<td>OpenAire, Zenodo, DOI</td>
</tr>
<tr>
<td>ISO19115:2005</td>
<td>Bonares, INSPIRE</td>
</tr>
</tbody>
</table>
<p>Metadata is harmonised to a <a href="https://www.w3.org/TR/vocab-dcat-3/" target="_blank">DCAT</a> RDF representation.</p>
<p>For metadata harmonization some supporting modules are used, <a href="https://owslib.readthedocs.io/en/latest/" target="_blank">owslib</a> is a module to parse various source metadata models, including iso19139:2007. A transformation script from (semic-eu/iso19139-to-dcat-ap.xslt)[https://github.com/semic-eu/iso19139-to-dcat-ap/] in combination with lxml and rdflib is used to convert iso19139:2007 metadata to RDF, serialised as turtle.</p>
<p>Harmonised metadata is either transformed to iso19139:2007 or Dublin Core and then ingested by the pycsw software, used to power the <a href="#technical_components-catalogue">SoilWise Catalogue</a>, using an automated process running at intervals. At this moment the pycsw catalogue software requires a dedicated database structure. This step converts the harmonised metadata database to that model. In next iterations we aim to remove this step and enable the catalogue to query the harmnised model directly.</p>
<h4 id="technical_components-ingestion-metadata-augmentation">Metadata Augmentation</h4>
<p>The metadata augmentation processes are described <a href="#technical_components-metadata_augmentation">elsewhere</a>, what is relevant here is that the output of these processes is integrated in the harmonised metadata database.</p>
<h3 id="technical_components-ingestion-metadata-rdf-turtle-serialization">Metadata RDF turtle serialization</h3>
<p>The harmonised metadata model is based on the DCAT ontology. In this step the content of the database is written to RDF.</p>
<p>Harmonized metadata is transformed to RDF in preparation of being loaded into the triple store (see also <a href="#technical_components-knowledge_graph">Knowledge Graph</a>).</p>
<h3 id="technical_components-ingestion-rdf-to-triple-store">RDF to Triple store</h3>
<p>This is a component which on request can dump the content of the harmonised database as an RDF quad store. This service is requested at intervals by the triple store component. In a next iteration we aim to push the content to the triple store at intervals.</p>
<h3 id="technical_components-ingestion-duplication-indentification">Duplication indentification</h3>
<p>A resource can be described in multiple Catalogues, identified by a common identifier. Each of the harvested instances may contain duplicate, alternative or conflicting statements about the resource. SoilWise Repository aims to persist a copy of the harvested content (also to identify if the remote source has changed). For this iteration we store the first copy, and capture on what other platforms the record has been discovered. OpenAire already has a mechanism to indicate in which platforms a record has been discovered, this information is ingested as part of the harvest. An aim of this exercise is also to understand in which repositories a certain resource is advertised.</p>
<p>Visualization of source repositories is in the first development iteration available as a dedicated section in the <a href="#technical_components-catalogue">SoilWise Catalogue</a>.</p>
<h2 id="technical_components-ingestion-technology">Technology</h2>
<h3 id="technical_components-ingestion-git-actionspipelines-to-run-harvest-tasks">Git actions/pipelines to run harvest tasks</h3>
<p>Git actions (github) or pipelines (gitlab) are automated processes which run at intervals or events. Git platforms typically offer this functionality including extended logging, queueing, and manual job monitoring and interaction (start/stop).</p>
<p>Each harvester runs in a dedicated container. The result of the harvester is ingested into a (temporary) storage.
Follow up processes (harmonization, augmentation, validation) pick up the results from the temporary storage. </p>
<p><pre  class="mermaid"><code>flowchart LR
    c[CI-CD] -->|task| q[/Queue\]
    r[Runner] --> q
    r -->|deploys| hc[Harvest container]
    hc -->|harvests| db[(temporary storage)]
    hc -->|data cleaning| db[(temporary storage)]
</code></pre>
Harvester tasks are triggered from <a href="https://github.com/features/actions" target="_blank"><strong>Git CI-CD</strong></a>, Git provides options to cancel and trigger tasks and review CI-CD logs to check errors</p>
<h4 id="technical_components-ingestion-ogc-csw_1">OGC-CSW</h4>
<p>Many (spatial) catalogues advertise their metadata via the <a href="https://www.ogc.org/standard/cat/" target="_blank">catalogue Service for the Web</a> standard, such as INSPIRE GeoPortal, Bonares, ISRIC.</p>
<h4 id="technical_components-ingestion-cordis-openaire">CORDIS - OpenAire</h4>
<p>Cordis does not capture many metadata properties. We harvest the title of a project publication and, if available, the DOI. In those cases where a resource is identified by a <a href="https://www.doi.org/the-identifier/what-is-a-doi/" target="_blank">DOI</a>, additional metadata can be found in OpenAire via the DOI. For those resources a harvester fetches additional metadata from OpenAire. </p>
<p>A second mechanism is available to link from Cordis to OpenAire, the RCN number. The OpenAire catalogue can be queried using an RCN filter to retrieve only resources relevant to a project. This work is still in preparation.</p>
<p>Not all DOI's registered in Cordis are available in OpenAire. OpenAire only lists resources with an open access license. Other DOI's can be fetched from the DOI registry directly or via Crossref.org. This work is still in preparation.
Detailed technical information can be found in the <a href="https://github.com/soilwise-he/harvesters/tree/main/cordis#readme" target="_blank">technical description</a>.</p>
<h4 id="technical_components-ingestion-openaire-and-other-sources">OpenAire and other sources</h4>
<p>The software used to query OpenAire by DOI or by RCN is not limited to be used by DOIs or RCNs that come from Cordis. Any list of DOIs or list of RCNs can be handled by the software.</p>
<h2 id="technical_components-ingestion-integration-opportunities">Integration opportunities</h2>
<p>The Automatic metadata harvesting component will show its full potential when being in the SWR tightly connected to (1) <a href="#technical_components-catalogue">SWR Catalogue</a>, (2) <a href="#technical_components-metadata_authoring">Metadata authoring</a> and (3) <a href="#technical_components-metadata_validation-metadata-etsats-checking">ETS/ATS</a>, i.e. test suites.</p></section><section class="print-page" id="technical_components-storage"><h1 id="technical_components-storage-repository-storage">Repository Storage</h1>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> Postgres release 12.2; Virtuoso release 07.20.3239</p>
<p><strong>Access point:</strong> Triple Store (SWR SPARQL endpoint) <a href="https://sparql.soilwise-he.containers.wur.nl/sparql">https://sparql.soilwise-he.containers.wur.nl/sparql</a></p>
</div>
<p>The SoilWise repository aims at merging and seamlessly providing different types of content. To host this content and to be able to efficiently drive internal processes and to offer performant end user functionality, different storage options are implemented.</p>
<ol>
<li><a href="#technical_components-storage-postgress-rdbms-storage-of-raw-and-augmented-metadata">A relational database management system</a> for the storage of the core metadata of both data and knowledge assets.</li>
<li><a href="#technical_components-storage-virtuoso-triple-store-storage-of-swr-knowledge-graph">A Triple Store</a> to store the metadata of data and knowledge assets as a graph, linked to soil health and related knowledge as a linked data graph.</li>
<li><a href="#technical_components-storage-git-user-enhanced-metadata">Git</a> for storage of user-enhanced metadata.</li>
</ol>
<h2 id="technical_components-storage-functionality">Functionality</h2>
<h3 id="technical_components-storage-postgress-rdbms-storage-of-raw-and-augmented-metadata">Postgress RDBMS: storage of raw and augmented metadata</h3>
<p>A "conventional" RDBMS is used to store the (augmented) metadata of data and knowledge assets. The harvester process uses it to store the raw results of the metadata harvesting of the different resources that are currently connected. Various metadata augmentation jobs use it as input and write their input to this data store.
The catalogue also queries the Postgress database. </p>
<p>There are several reasons for choosing an RDBMS as the main source for metadata storage and metadata querying</p>
<ul>
<li>An RDBMS provides good options to efficiently structure and index its contents, thus allowing performant access for both internal processes and end user interface querying.</li>
<li>An RDBMS easily allows implementing constraints and checks to keep data and relations consistent and valid.</li>
<li>Various extensions, e.g. search engines, are available to make querying, aggregations even more performant and fitted for end users.</li>
</ul>
<h3 id="technical_components-storage-virtuoso-triple-store-storage-of-swr-knowledge-graph">Virtuoso Triple Store: storage of SWR knowledge graph</h3>
<p>A Triple Store is implemented as part of the SWR infrastructure to allow a more flexible linkage between the knowledge captured as metadata and various sources of internal and external knowledge sources, particularly taxonomies, vocabularies and ontologies that are implemented as RDF graphs. Results of the harvesting and metadata augmentation that are stored in the RDBMS are converted to RDF and stored in the Triple Store. </p>
<p>A Triple Store is selected as a parallel storage because it offers several capabilites </p>
<ul>
<li>It allows the linking of different knowledge models, e.g. to connect the SWR metadata model with existing and new knowledge structures on soil health and related domains.</li>
<li>It allows reasoning over the relations in the stored graph, and thus allows connecting and smartly combining knowledge from those domains.</li>
<li>Through the SPARQL interface, it allows users and processes to use such reasoning and exploit previously unconnected sets of knowledge.</li>
</ul>
<h3 id="technical_components-storage-git-user-enhanced-metadata">Git: User enhanced metadata</h3>
<p>The current setup of SWR, using the pycsw infrastructure, allows users to propose metadata enhancements. Such enhancements are managed in Git at: <a href="https://github.com/soilwise-he/soilinfohub/discussions">https://github.com/soilwise-he/soilinfohub/discussions</a>.</p>
<h2 id="technical_components-storage-ongoing-developments">Ongoing Developments</h2>
<p>In the next iteration of the SWR development, the currently deployed storage options will be extended to support new features and functions. Such extensions can improve performance and usability. Moreover, we expect that the integration of AI/ML based functions will require additional types of storage and better a integration to exploit their combined power. Exploratory work that was performed, but is not yet integrated into the deployment of iteration 1 include:</p>
<h3 id="technical_components-storage-establishing-a-vector-database">Establishing a vector database</h3>
<p>A vector database is foreseen as a foundation to use Large Language Models (LLM) and implement Natural Language Querying (NLQ), e.g. to allow chatbot functionality for end users. A vector DB allows storage of text embeddings that are a the basis for such NLQ functions.</p>
<h3 id="technical_components-storage-selecting-a-search-engine">Selecting a search engine</h3>
<p>A search engine, deployed on top of the current RDBMS, will increase the perfomance of end user queries. It can also offer better usability, e.g. by offering aggregation functions for faceted search and ranking of search results. Additionally, search engines are also implementing the indexation of unstructured content and are moving to supporting text embeddings. Thus, they might be a starting point (or alternative?) to offer smart searches on unstructured text, using more conventional and broadly adopted software and offering easier migration pathways towards NLQ-like functions. </p>
<h2 id="technical_components-storage-technology-integration">Technology &amp; Integration</h2>
<p>Components used:</p>
<ul>
<li>Virtuoso (version 07.20.3239)</li>
<li>PostgreSQL (release 12.13)</li>
</ul>
<!-- HERE'S FOR REFERENCE, THE PREVIOUS CONTENT

The SoilWise Repository is expected to fulfil the following functions:

1. [Storage of artefacts](#storage-of-artefacts)
2. [Storage of metadata](#storage-of-metadata)
3. [Storage of data](#storage-of-data)
4. [Storage of knowledge](#storage-of-knowledge)
5. [Backup and versioning](#backup-and-versioning)

## Technology

Various storage options exist, dedicated usage scenarios usually have an optimal storage option. Maintenance will also be considered as part of the choice.

- **Relational databases** provide performant filtering and aggregation options that facilitate the performance of data APIs. Relational databases have a fixed data model. 
- **Search engines**, such as SOLR/Elastic search. Search engines provide even higher performance and introduce faceted search (aggregations) and ranking customisation.
- **File (& bucket) repositories**, which are slow and non-queryable but very flexible in the data model, scalable and persistent.
- **Graph and triple stores**, which are very fitted to store relations between random entities and can reason over data in multiple domain models.
- **Versioning systems** (such as git), which are very slow and not queryable but ultimately persistent/traceable. Less optimal for binary files.


## Storage of artefacts

### Data model

‘To which data model shall I align?’ is the central question of data harmonisation efforts and data interoperability in general. SoilWise is aware of the fragmentation of soil data and the lack of harmonisation. As such, the SWR will, in the first project iteration cycle, focus on two major pan-European/global data modelling efforts within the soil domain. 

-  **GloSIS** (Global Soil Information System) is the name for the system and the soil data model, also named the GloSIS domain model. The GloSIS domain model published as a UML class diagram is not publicly available, being in the FAO repositories under the CC <by-nc-sa/3.0/igo> license. Nevertheless, the [GloSIS web ontology](https://www.semantic-web-journal.net/system/files/swj3589.pdf){target=_blank} is publicly available implementation with the Web Ontology Language (OWL). The GloSIS web ontology employs a host of Semantic Web standards (SOSA, SKOS, GeoSPARQL, QUDT); GloSIS lays out not only a soil data ontology but also an extensive set of ready-to-use code lists for soil description and physio-chemical analysis. Various examples are provided on the provision and use of GloSIS-compliant linked data, showcasing the contribution of this ontology to the discovery, exploration, integration and access of soil data.
- **INSPIRE** (INfrastructure for SPatial InfoRmation in Europe) aiming to create a spatial environmental data infrastructure for the European Union. A detailed [data specification for the soil theme](https://github.com/INSPIRE-MIF/technical-guidelines/tree/main/data/so){target=_blank} was published by the European Commission in 2013, supported by a detailed domain model documented as a [UML class diagram](https://inspire-mif.github.io/uml-models/approved/ea+xmi/EAXMI.zip){target=_blank}.


Other (potentially) relevant data models are:

- [World Reference base (WRB)](https://wrb.isric.org/){target=_blank} maintains the code lists, which are the source of GLOSIS codelists, but the WRB online presence is currently limited.
- [Landuse](https://inspire.ec.europa.eu/theme/lu){target=_blank}
- [Land management practices](https://qcat.wocat.net/en/wocat/){target=_blank}
- [monitoring facilities](https://inspire.ec.europa.eu/theme/ef){target=_blank}
- [Landcover](https://inspire.ec.europa.eu/theme/lc){target=_blank}

#### Open issues

Many data models are used for data harmonisation and interoperability within the soil domain. The following data models may also be potentially relevant for the SWR:

- **SOTER**: the Global and National Soils and Terrain Digital Databases (SOTER) was chronologically the first global soil spatial data harmonisation/interoperability initiative of the International Society of Soil Science (ISSS), in cooperation with the United Nations Environment Programme, the International Soil Reference and Information Centre (ISRIC) and the FAO. Albeit lacking an abstract formalisation (SOTER pre-dates both UML and OWL), the ancient SOTER databases remained a reference for developing subsequent soil information models.
- **ISO 28258**, “Soil quality — Digital exchange of soil-related data” as one of the key achievements of the GS Soil project. This standard produced a general framework for exchanging soil data, recognising a need to combine soil with other kinds of data. ISO 28258 is documented with a UML domain model, applying the O&M framework to the soil domain. An XML exchange schema is derived from this domain model, adopting the Geography Markup Language (GML) to encode geospatial information. The standard was conceived as an empty container, lacking any kind of controlled content. It is meant to be further specialised for actual use (possibly at a regional or national scale).
- **ANZSoilML**, the Australian and New Zealand Soil Mark-up Language (ANZSoilML), results from a joint effort by CSIRO in Australia and New Zealand’s Manaaki Whenua to support the exchange of soil and landscape data. Its domain model was possibly the first application of O&M to the soil domain, targeting the soil properties and related landscape features specified by
the institutional soil survey handbooks used in Australia and New Zealand. ANZSoilML is formalised as a UML domain model from which an XML schema is obtained, relying on the ComplexFeature abstraction that underlies the SOAP/XML web services specified by the OGC. A set of controlled vocabularies was developed for ANZSoilML, providing values for categorical soil properties and laboratory analysis methods. More recently, these vocabularies were transformed into RDF resources to be managed with modern Semantic Web technologies.

Moreover, GloSIS and INSPIRE data models fully support only vector data. GloSIS has not developed a data model for gridded data yet, and several issues were reported to the INSPIRE data model for gridded data.

GloSIS and INSPIRE soil are oriented to Observations and Measurements of OGC, with the arrival of the samples objects in the new version of O&M, now named [Observations Measurements & Samples](https://www.ogc.org/standard/om/){target=_blank}. Soilwise can probably contribute to the migration of the soil models to the new OMS version.

### Soil health vocabulary 

Understand if Soil health codelists as developed in the Envasso and Landmark projects, can be adopted by the online soil community, for example, as part of the Glosis ontology, INSPIRE registry or EUSO. Research is needed to evaluate if a legislative body is available to confirm the definitions of the terms.

## Storage of metadata

- Metadata is best stored on a git versioning system to trace its history and facilitate community contributions.
- Metadata is best stored in a graph database or triple store to validate interlinkage and facilitate harmonisation.
- Metadata is best queried from a database or search engine. Search engines, by default, offer ranking and faceting capabilities, which are hard to reproduce on databases, but search engines come at a high cost in terms of maintenance and memory use.
- All collected metadata will be archived once per year.
- Besides raw metadata, the results of the metadata validation process will be stored along with override values.

## Storage of knowledge

-   Storage (or non-storage) of knowledge is highly dependent on the type of knowledge, how it is to be used and the available resources for storage. 
-   As a minimum SWR stores metadata describing knowledge assets (unstructured content) – see section [storage of metadata](#storage-of-metadata).
-   Knowledge that expresses links between data and knowledge assets is best stored in a graph DB or an RDF DB, depending also on the application requirements.
-   Knowledge that expresses semantics is best stored as RDF in an RDF DB, to be able to reason over semantic relationships.
-   When knowledge needs to be reasoned over using LLMs, it is preferably processed and stored in a vector DB, potentially linked to relevant text fragments (for explainable AI). 
-   Querying knowledge is best done from an indexed DB or search engine (see section metadata) or from a vector DB (through chatbot / LLM applications).


### Knowledge graph - Triple Store

The knowledge graph is meant to add a formal semantics layer to the metadata collected at the SWR. It mirrors the XML-based metadata harnessed in the Catalogue Server but uses Semantic Web standards such as DCAT, Dublin Core, VCard or PROV. This metadata is augmented with links to domain web ontologies, in particular GloSIS. This semantically augmented metadata is the main pillar of knowledge extraction activities and components.

Besides metadata on knowledge assets, the knowledge graph is also expected to host the results of knowledge extraction activities. This assumes knowledge to be semantically loaded, i.e. linking to relevant domain ontologies. The identification of appropriate ontologies and ontology mappings thus becomes an essential aspect of this project, bridging together various activities and assets.

It is important to recognise the knowledge graph as an immaterial asset that cannot exist by itself. In order to be usable the knowledge graph must be stored in a triple store, thus highlighting the role of that component in the architecture. In its turn the triple store provides another important architectural component, the SPARQL end-point. That will be the main access gateway to the knowledge graph, particularly through other technological components and software.

The [Natural Language Querying](natural_language_querying.md) functionality foreseen in this project will, amongst others, use the formal knowledge graph, e.g. as part of a Chatbot component of the user interface. The knowledge graph will further feed the facilities for machine-based access to the SWR: a knowledge extraction API and a SPARQL end-point.

#### Technology
- DCAT, Dublin Core, VCard, PROV, GloSIS


## Storage of data

### Processed data

- Data that changes often (due to continuous ingested data feeds) are best stored in a database.
- Snapshots of data feeds or data processing results are best stored as files on a repository or bucket, and the file location (in combination with an identification proxy, like DOI) provides a unique identification of the dataset.
- API access to larger datasets best uses a scalable database or files in a cloud native (scalable) format. Data is exported to such formats before exposure via APIs (from git, triple stores, files, etc). in some cases, a search engine is the most relevant API backend.

### High-value data

- Full dataset download or Single band data (access by bbox, not by property) is best stored as files on a scalable file infrastructure using cloud native formats, where the file location provides the identification.
- Data that is frequently filtered or aggregated on attribute value is best stored on a relational database or search engine.

### Temporary store for uploaded data

Temporary data storage may be necessary as a caching mechanism to achieve acceptable performance (e.g. response time and throughput), e.g. for derived and harmonised data sets. For any data that is supposed to be stored temporarily, there shall be a flag that indicates its validity until it shall be cleaned up. The monitoring system shall check whether any such flags are present that should have been cleaned up already.

### Technology

- **PostgreSQL** is a common open-source database platform with spatial support. A database dump of a Postgres database, as a backup or to publish FAIR versions at intervals, is not very user-friendly. A conversion to **SQLite/GeoPackage** (using GDAL/Hale) facilitates this case.
- The most popular search engine is **Elastic Search** (also used by JRC in INSPIRE), but has some challenges in its license. Alternative is **SOLR**.
- File repositories range from Amazon/Google to a local NFS with Webdav access.
- Graph database **Neo4J**, **Triple store**, **Jena Fuseki** (Java) or **Virtuoso** (C) both have spatial support.
- **GIT** is the most used versioning system these days, with the option to go for SAAS (Github, Bitbucket) or on-premise (Gitlab). GitHub seems the most suitable option, as other groups such as OGC and INSPIRE are already there, which means users already have an account, and we can cross-link issues between projects.

## Backup and versioning

For any data, there shall be at least two levels of backups. Volume snapshots shall be the preferred mode of backups. These volume snapshots should be stored in a different location and should enable fast recovery (i.e. in less than 4 hours during business hours) even if the location where the SWR is operated is entirely unavailable. These volume snapshots should be configured in such a way that at no point in time, more than 1 hour of new data/changed data would be lost. Volume backups should be retained for 30 days.

A second level of backups can be more granular, e.g., storing all data and metadata assets, as well as configuration and system data as encrypted files in an object store such as AWS S3. This type of backup allows for a more specific or partial recovery for cases where data integrity was damaged, where there was a partial data loss or another incident which does not necessitate restoring the system. This could also include explicit backups (dumps) of the database systems that are part of the SWR. It is tolerable for these backups to be updated once per day.

If there is data that requires full versioning or historisation, it is recommended to store it in a version control system.

Finally, there should be a restore exercise at least once per year, where a fresh system is set up from both types of backups.

--></section><section class="print-page" id="technical_components-catalogue"><h1 id="technical_components-catalogue-catalogue">Catalogue</h1>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 0.1.0</p>
<p><strong>Project:</strong> <a href="https://github.com/soilwise-he/pycsw">pycsw</a></p>
<p><strong>Access point:</strong> <a href="https://soilwise-he.containers.wur.nl/cat/">https://soilwise-he.containers.wur.nl/cat/</a></p>
</div>
<p>The metadata catalogue is a central piece of the architecture, 
giving access to individual metadata records. In the catalogue domain,
various effective metadata catalogues are developed around the standards issued by the
OGC, the <a href="https://www.ogc.org/standard/cat/" target="_blank">Catalogue Service for the Web</a>
(CSW) and the <a href="https://ogcapi.ogc.org/records/" target="_blank">OGC API Records</a>, Open Archives Initiative (OAI-PMH), W3C (DCAT), FAIR science (Datacite) and Search Engine community (schema.org). For our first iteration we've selected the pycsw software, which supports most of these standards. </p>
<h2 id="technical_components-catalogue-functionality">Functionality</h2>
<p>The SoilWise prototype adopts a frontend, focusing on:</p>
<ul>
<li>minimalistic User Interface, to prevent a technical feel,</li>
<li>paginated search results, sorted alphabetically, by date, see more information in Chapter <a href="#technical_components-catalogue-query-catalogue">Query Catalogue</a>,</li>
<li>option to filter by facets, see more information in Chapter <a href="#technical_components-catalogue-query-catalogue">Query Catalogue</a>,</li>
<li>preview of the dataset (if a thumbnail or OGC:Service is available), else display of its spatial extent, see more information in Chapter <a href="#technical_components-catalogue-display-records-detail">Display record's detail</a>,</li>
<li>option to provide feedback to publisher/author, see more information in Chapter <a href="#technical_components-catalogue-user-engagement">User Engagement</a>,</li>
<li>readable link in the browser bar, to facilitate link sharing.</li>
</ul>
<h3 id="technical_components-catalogue-query-catalogue">Query Catalogue</h3>
<p>The SoilWise Catalogue currently enables the following search options:</p>
<ul>
<li><a href="#technical_components-catalogue-fulltext-search">fulltext search</a></li>
<li><a href="#technical_components-catalogue-faceted-search">faceted search</a></li>
</ul>
<p>50 results are displayed per page in alphabetical order, in the form of overview table comprising preview of title, abstract, contributor, type and date. Search items set through user interface is also reflected in the URL to facilitate sharing.</p>
<h3 id="technical_components-catalogue-fulltext-search">Fulltext search</h3>
<p>Fulltext search is currently enabled through the q= attribute. Other queryable parameters are title, keywords, abstract, contributor. Full list of queryables can be found at: <a href="https://soilwise-he.containers.wur.nl/cat/collections/metadata:main/queryables">https://soilwise-he.containers.wur.nl/cat/collections/metadata:main/queryables</a>.</p>
<p>Fulltext search currently supports only nesting words with AND operator.</p>
<h3 id="technical_components-catalogue-faceted-search">Faceted search</h3>
<ul>
<li>filter by <strong>physical soil parameters</strong> (soil texture, WRB, soil structure, bulk density, porosity, water holding capacity, soil moisture),</li>
<li>filter by <strong>chemical soil parameters</strong> (ph, organic matter, cation exchange capacity, electrical conductivity, nutrient content, soil carbon, soil nitrogen, soil phosporus, heavy metals concentration),</li>
<li>filter by <strong>biological soil parameters</strong> (microbial biomass, soil enzyme activities, soil fauna, soil respiration),</li>
<li>filter by <strong>soil functions</strong> (soil fertility, water regulation, soil erosion control, carbon sequestration, soil health, supporting plant growth, contaminant filtration),</li>
<li>filter by <strong>soil degradation indicators</strong> (soil erosion, soil compaction, soil salinization, soil acidification, soil contamination),</li>
<li>filter by <strong>environmental soil functions</strong> (habitat for organisms, climate regulation, water filtration),</li>
<li>fitler by <strong>long-term field experiments</strong> (experimental treatments, temporal data, environmental covariates, soil productivity, soil management),</li>
<li>filter by <strong>record's type</strong> (dataset, document, publication, software, services, series).</li>
</ul>
<h4 id="technical_components-catalogue-future-work">Future work</h4>
<ul>
<li>extend fulltext search; allow complex queries using exact match, OR,...</li>
<li>use Full Text Search ranking to sort by relevance.</li>
<li>filter by source repository.</li>
</ul>
<h3 id="technical_components-catalogue-display-records-detail">Display record's detail</h3>
<p>After clicking result's table item, a record's detail is displayed at unique URL address to facilitate sharing. Record's detail currently comprises:</p>
<ul>
<li>record's type tag,</li>
<li>full title,</li>
<li>full abstract,</li>
<li>keywords' tags,</li>
<li>preview of record's geographical extent, see <a href="#technical_components-catalogue-map-preview">Map preview</a>,</li>
<li>record's preview image, if available,</li>
<li>all other record's items,</li>
<li>section enabling <a href="#technical_components-catalogue-user-engagement">User Engagement</a>,</li>
<li>last update date.</li>
</ul>
<h4 id="technical_components-catalogue-future-work_1">Future work</h4>
<ul>
<li>links section with links to original repository, <em>TBD</em>...,</li>
<li>indication of metadata augmentation, such as link liveliness assessment,</li>
<li>display metadata augmentation results,</li>
<li>display metadata validation results,</li>
<li>show relations to other records,</li>
<li>better distinguish link types; service/api, download, records, documentation, etc.</li>
</ul>
<h3 id="technical_components-catalogue-resource-preview">Resource preview</h3>
<p>SoilWise Catalogue currently supports 3 types of preview:</p>
<ul>
<li>Display resource geographical extent, which is available in the record's detail, as well in the search results list.</li>
<li>Display of a graphic preview (thumbnail) in case it is advertised in metadata.</li>
<li>Map preview of OGC:WMS services advertised in metadata enables standard simple user interaction (zoom, changing layers).</li>
</ul>
<h3 id="technical_components-catalogue-data-download-as-is">Data download (AS IS)</h3>
<p>Download of data "as is" is currently supported through the links section from the harvested repository. Note, "interoperable data download" has been only a proof-of-concept in the first iteration phase, i.e. is not integrated into the SoilWise Catalogue.</p>
<h3 id="technical_components-catalogue-display-link-to-knowledge">Display link to knowledge</h3>
<p>Download of knowledge source "as is" is currently supported through the links section from the harvested repository.</p>
<h3 id="technical_components-catalogue-support-catalogue-apis-of-various-communities">Support catalogue API's of various communities</h3>
<p>In order to interact with the many relevant data communities, Soilwise aims to support a range of catalogue standards.</p>
<h4 id="technical_components-catalogue-catalogue-service-for-the-web">Catalogue Service for the Web</h4>
<p>Catalogue service for the web (CSW) is a standardised pattern to interact with (spatial) catalogues, maintained by OGC. </p>
<h4 id="technical_components-catalogue-ogc-api-records">OGC API - Records</h4>
<p>OGC is currently in the process of adopting a revised edition of its catalogue standards. The new standard is called OGC API - Records. OGC API - Records is closely related to Spatio Temporal Asset Catalogue (STAC), a community standard in the Earth Observation community. </p>
<h4 id="technical_components-catalogue-protocol-for-metadata-harvesting">Protocol for metadata harvesting</h4>
<p>The open archives initiative has defined a common protocol for metadata harvesting (oai-pmh), which is adopted by many catalogue solutions, such as Zenodo, OpenAire, CKAN. The oai-pmh endpoint of Soilwise can be harvested by these repositories.</p>
<h4 id="technical_components-catalogue-schemaorg-annotiations">Schema.org annotiations</h4>
<p>Annotiations using <a href="https://schema.org/Dataset">schema.org/Dataset</a> ontology enable search engines to harvest metadata in a structured way.</p>
<h3 id="technical_components-catalogue-user-engagement">User Engagement</h3>
<p>Collecting users feedback provides an important channel on the usability of described resources. Users can even support each other by sharing the feedback as 'questions and answers'. For this purpose every display of a record is concluded with a feedback section where users can interact about the resource. Users need to authenticate to provide feedback.</p>
<h4 id="technical_components-catalogue-future-work_2">Future work</h4>
<p>Notify the resource owners of incoming feedback, so they can answer any questions or even improve their resource.</p>
<h2 id="technical_components-catalogue-technology">Technology</h2>
<p><a href="https://pycsw.org" target="_blank">pycsw</a>  is a catalogue component offering an HTML frontend and query interface using various standardised catalogue APIs to serve multiple communities. Pycsw, written in python, allows for the publishing and discovery of geospatial metadata via numerous APIs (<a href="https://www.ogc.org/standard/cat/" target="_blank">CSW 2/CSW 3</a>, <a href="https://opensearch.org/" target="_blank">OpenSearch</a>, <a href="https://www.openarchives.org/pmh/" target="_blank">OAI-PMH</a>, <a href="https://developers.exlibrisgroup.com/rosetta/integrations/standards/sru/" target="_blank">SRU</a>), providing a standards-based metadata and catalogue component of spatial data infrastructures. pycsw is <a href="https://opensource.org/" target="_blank">Open Source</a>, released under an <a href="https://docs.pycsw.org/en/latest/license.html" target="_blank">MIT license</a>, and runs on all major platforms (Windows, Linux, Mac OS X).</p>
<p>pycsw is deployed as a docker container from the official docker hub repository. Its configuration is updated at deployment. Some layout templates are overwritten at deployment to facilitate a tailored HTML view.</p>
<h2 id="technical_components-catalogue-integration">Integration</h2>
<p>The SWR catalogue component will show its full potential when integrated to (1) <a href="#technical_components-ingestion">Harvester</a>, (2) <a href="#technical_components-storage-storage-of-metadata">Storage of metadata</a>,  (3) <a href="#technical_components-metadata_augmentation">Metadata Augmentation</a> and <a href="#technical_components-metadata_validation">Metadata Validation</a>. </p></section><section class="print-page" id="technical_components-metadata_validation"><h1 id="technical_components-metadata_validation-metadata-validation">Metadata Validation</h1>
<blockquote>
<p>Metadata should help users assess the usability of a data set for their own purposes and help users to understand their quality.</p>
</blockquote>
<p>In terms of metadata, SoilWise Repository aims for the approach to harvest and register as much as possible (see more information in the <a href="#technical_components-ingestion">Harvester Component</a>). Catalogues which capture metadata authored by data custodians typically have a wide range of metadata completion and accuracy. Therefore, the SoilWise Repository employs metadata validation mechanisms to provide additional information about metadata completeness, conformance and integrity. Information resulting from the validation process are stored together with each metadata record in a relation database and updated after registering a new metadata version. Within the first iteration, they are not displayed in the <a href="#technical_components-catalogue">SoilWise Catalogue</a>, except of the results of the <a href="#technical_components-metadata_validation-link-liveliness-assessment">Link liveliness assessment</a> component. For the following iterations, we forsee the validation results to be available only to data / knowledge owners / managers and the SWR admins, as SoilWise is not in an arbiter's role.</p>
<p>After <a href="#technical_components-metadata_augmentation">Metadata augmentation</a>, the whole validation process can be repeated to understand the variability of metadata and value which has been added by SWR.</p>
<p>Validations:</p>
<ul>
<li><a href="#technical_components-metadata_validation-metadata-profile-validation">Metadata profile validation</a></li>
<li><a href="#technical_components-metadata_validation-link-liveliness-assessment">Link liveliness assessment</a></li>
</ul>
<h2 id="technical_components-metadata_validation-metadata-profiles">Metadata profiles</h2>
<p>Metadata profiles specify the required metadata elements that must be included to describe resources, ensuring they are discoverable, accessible, and usable. Metadata validation is inherently linked to the specific metadata profile it is intended to follow. This linkage ensures that metadata records are consistent, meet the necessary standards, and are fit for their intended purpose, thereby supporting effective data management, discovery, and use. In the soil domain, several metadata profiles are commonly used to ensure the effective documentation, discovery, and utilization of soil data, for example Datacite, GBIF-EML, Geo-DCAT-AP, INSPIRE Metadata Profile, Dublin Core, ANZLIC Metadata Profile, FAO Global Soil Partnership Metadata Profile, EJP/EUSO Metadata Profile. SoilWise Repository is currently able to perform validations according to the following metadata profiles:</p>
<!--
### Minimal metadata elements

A minimal set of metadata elements was defined to validate completeness of metadata record against the optimal performace prerequisites of SWR platform.

| Label | Description |
| ---   | ---         |
| Identification | Unique identification of the dataset (A UUID, URN, or URI, such as DOI) |
| Title | Short meaningful title |
| Abstract | Short description or abstract (1/2 page), can include (multiple) scientific/technical references |
| Contributor | An entity responsible for making contributions to the content of the resource (e.g. person or organisation name) |
| Date | Last update date | 
| Type | The nature or genre of the content of the resource |
| Rights | Information about rights and licences |
| Extent (geographic) | Geographical coverage (e.g. EU, EU & Balkan, France, Wallonia, Berlin) |
| Online source | Location (address) for online access from which the resource can be obtained |
-->

<h3 id="technical_components-metadata_validation-euso-metadata-profile">EUSO Metadata profile</h3>
<p>This metadata profile was developed through EJP Soil project efforts and modified and approved by the EUSO Working Group.</p>
<p>This metadata profile has been used within the first development iteration phase. Its further modification are under discussions among all the stakeholders.</p>
<table>
<thead>
<tr>
<th>Label</th>
<th>Cardinality</th>
<th>Codelist</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Identification</td>
<td>1-n</td>
<td></td>
<td>Unique identification of the dataset (A UUID, URN, or URI, such as DOI)</td>
</tr>
<tr>
<td>Title</td>
<td>1-1</td>
<td></td>
<td>Short meaningful title</td>
</tr>
<tr>
<td>Abstract</td>
<td>1-1</td>
<td></td>
<td>Short description or abstract (1/2 page), can include (multiple) scientific/technical references</td>
</tr>
<tr>
<td>Extent (geographic)</td>
<td>0-1</td>
<td>BBOX or Geonames</td>
<td>Geographical coverage (e.g. EU, EU &amp; Balkan, France, Wallonia, Berlin)</td>
</tr>
<tr>
<td>Reference period - Start</td>
<td>0-1</td>
<td></td>
<td>Reference period for the data - Start</td>
</tr>
<tr>
<td>Reference period - End</td>
<td>0-1</td>
<td></td>
<td>Reference period - End; empty if ongoing</td>
</tr>
<tr>
<td>Access constraints</td>
<td>1-1</td>
<td>INSPIRE</td>
<td>Indicates if the data is publicly accessible or the reason to apply access constaints</td>
</tr>
<tr>
<td>Usage constraints</td>
<td>1-1</td>
<td>INSPIRE</td>
<td>Indicates if there are legal usage constraints (license)</td>
</tr>
<tr>
<td>Keywords</td>
<td>0-n</td>
<td></td>
<td>Keywords</td>
</tr>
<tr>
<td>Contact</td>
<td>1-n</td>
<td></td>
<td>name; organisation; email; role, where role is one of distributor, owner, pointOfContact, processor, publisher, metadata-contact</td>
</tr>
<tr>
<td>Source</td>
<td>0-n</td>
<td></td>
<td>Source is a reference to another dataset which is used as a source for this dataset. Reference a single dataset per line; Title; Date; or provide a DOI;</td>
</tr>
<tr>
<td>isSourceOf</td>
<td>0-n</td>
<td></td>
<td>Other datasets that the current dataset is used as input source</td>
</tr>
<tr>
<td>Lineage</td>
<td>1-1</td>
<td></td>
<td>Statement on the origin and processing of the data</td>
</tr>
<tr>
<td>Processing steps</td>
<td>0-n</td>
<td></td>
<td>Methods applied in data acquisition and processing: preferably reference a method from a standard (national, LUCAS, FAO, etc.). One processing step per line; Method; Date; Processor; Method reference; Comment</td>
</tr>
<tr>
<td>Language</td>
<td>1-n</td>
<td>ISO</td>
<td>Language, of the data and metadata, if metadata is multilingual multiple languages can be provided</td>
</tr>
<tr>
<td>Reference system</td>
<td>0-1</td>
<td>CRS</td>
<td>Spatial Projection: drop down list of options, including ‘unknown’  (you can also leave out the field if it is unknown)</td>
</tr>
<tr>
<td>Citation</td>
<td>0-n</td>
<td></td>
<td>Citations are references to articles which reference this dataset; one citation on each line; Title; Authors; Date; or provide a DOI</td>
</tr>
<tr>
<td>Spatial resolution</td>
<td>0-n</td>
<td></td>
<td>Resolution (grid) or scale (vector)</td>
</tr>
<tr>
<td>Data type</td>
<td>0-1</td>
<td>table, vector, grid</td>
<td>The type of data</td>
</tr>
<tr>
<td>Geometry type</td>
<td>0-1</td>
<td>point, line, polygon, ...</td>
<td>Geometry type for vector data</td>
</tr>
<tr>
<td>File / service Location</td>
<td>0-n</td>
<td></td>
<td>Url or path to the data file or service</td>
</tr>
<tr>
<td>Format</td>
<td>0-n</td>
<td>IANA</td>
<td>File Format in which the data is maintained or published</td>
</tr>
<tr>
<td>Delivery</td>
<td>0-n</td>
<td></td>
<td>The  way the dataset is available (ie digital: download, viewer OR physical way: Shipping or in situ access )</td>
</tr>
<tr>
<td>Maintenenance frequency</td>
<td>0-1</td>
<td>ISO</td>
<td>Indication of the frequency of data updates</td>
</tr>
<tr>
<td>Modification date</td>
<td>0-1</td>
<td></td>
<td>Date of last modification</td>
</tr>
<tr>
<td>Status</td>
<td>0-1</td>
<td>ISO</td>
<td>Status of the dataset</td>
</tr>
<tr>
<td>Subject - Spatial scope</td>
<td>0-n</td>
<td>INSPIRE</td>
<td>The scope of the dataset, e.g. regional, national, continental</td>
</tr>
<tr>
<td>Subject - Soil properties</td>
<td>0-n</td>
<td>INSPIRE</td>
<td>Soil properties described in this dataset</td>
</tr>
<tr>
<td>Subject - Soil function</td>
<td>0-n</td>
<td>INSPIRE</td>
<td>Soil funtions described in this dataset</td>
</tr>
<tr>
<td>Subject - Soil threats</td>
<td>0-n</td>
<td>INSPIRE</td>
<td>Soil threats described in this dataset</td>
</tr>
<tr>
<td>Subject - Soil Indicators</td>
<td>0-n</td>
<td>INSPIRE</td>
<td>Soil indicators  described in this dataset</td>
</tr>
<tr>
<td>Subject - EUSO Data WG subgroup</td>
<td>0-n</td>
<td>EUSO</td>
<td>The EUSO subgroups which contributed to this record</td>
</tr>
<tr>
<td>Subject - Context</td>
<td>0-n</td>
<td>EUSO</td>
<td>Context: (e.g. EU-Project SOILCARE, EJP-Soil, Literature, ESDAC, etc.) </td>
</tr>
<tr>
<td>Subject - Possible End-users</td>
<td>0-n</td>
<td>EUSO</td>
<td>Possible end-users: citizens, scientific community, private sector, EU, member states, academia</td>
</tr>
<tr>
<td>Subject - Category</td>
<td>0-n</td>
<td>EUSO</td>
<td>One or more thematic categories of the dataset</td>
</tr>
<tr>
<td>Quality statement</td>
<td>0-1</td>
<td></td>
<td>A statement of quality or any other supplemental information</td>
</tr>
<tr>
<td>Datamodel/dimensions</td>
<td>0-1</td>
<td></td>
<td>The datamodel (table) or dimensions (grid) of the dataset</td>
</tr>
<tr>
<td>Units of measure</td>
<td>0-n</td>
<td>ISU</td>
<td>List of UoM from International System of Units, at attribute/dimension level</td>
</tr>
<tr>
<td>Attribute type</td>
<td>0-n</td>
<td>string, number, date</td>
<td>The type of attribute</td>
</tr>
<tr>
<td>Categorical Data</td>
<td>0-n</td>
<td></td>
<td>Lookup tables for categorical data, at attribute/dimension level</td>
</tr>
<tr>
<td>Uncertainty</td>
<td>0-n</td>
<td></td>
<td>Method used to assess uncertainty and its result. For example: One or more measurements to describe the error and uncertainties in the dataset</td>
</tr>
<tr>
<td>Completeness</td>
<td>0-1</td>
<td></td>
<td>The % of completeness</td>
</tr>
</tbody>
</table>
<h3 id="technical_components-metadata_validation-inspire-metadata-profile">INSPIRE metadata profile</h3>
<p>The validation against the INSPIRE metadata profile checks whether the metadata records are in accordance with the technical requirements of INSPIRE, specifically according to the <a href="https://inspire-mif.github.io/technical-guidelines/data/so/dataspecification_so.pdf">INSPIRE data specification on Soil – Technical Guidelines</a> version 3.0. The Soil-specific metadata elements are: </p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Package Stereotypes</th>
</tr>
</thead>
<tbody>
<tr>
<td>DerivedProfilePresenceInSoilBody</td>
<td>«associationType»</td>
</tr>
<tr>
<td>DerivedSoilProfile</td>
<td>«featureType»</td>
</tr>
<tr>
<td>FAOHorizonMasterValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>FAOHorizonNotationType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>FAOHorizonSubordinateValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>FAOPrimeValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>LayerGenesisProcessStateValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>LayerTypeValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>ObservedSoilProfile</td>
<td>«featureType»</td>
</tr>
<tr>
<td>OtherHorizonNotationType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>OtherHorizonNotationTypeValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>OtherSoilNameType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>OtherSoilNameTypeValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>ParticleSizeFractionType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>ProfileElement</td>
<td>«featureType»</td>
</tr>
<tr>
<td>ProfileElementParameterNameValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>RangeType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>SoilBody</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilDerivedObject</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilDerivedObjectParameterNameValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>SoilHorizon</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilInvestigationPurposeValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>SoilLayer</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilPlot</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilPlotTypeValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>SoilProfile</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilProfileParameterNameValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>SoilSite</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilSiteParameterNameValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>SoilThemeCoverage</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilThemeDescriptiveCoverage</td>
<td>«featureType»</td>
</tr>
<tr>
<td>SoilThemeDescriptiveParameterType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>SoilThemeParameterType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>WRBQualifierGroupType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>WRBQualifierPlaceValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>WRBQualifierValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>WRBReferenceSoilGroupValue</td>
<td>«codelist»</td>
</tr>
<tr>
<td>WRBSoilNameType</td>
<td>«dataType»</td>
</tr>
<tr>
<td>WRBSpecifierValue</td>
<td>«codelist»</td>
</tr>
</tbody>
</table>
<h2 id="technical_components-metadata_validation-functionality">Functionality</h2>
<h3 id="technical_components-metadata_validation-metadata-profile-validation">Metadata profile validation</h3>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 0.1.0</p>
<p><strong>Project:</strong> <a href="https://github.com/soilwise-he/metadata-validator">Metadata validator</a></p>
<p><strong>Access point:</strong> <a href="https://data.soilwise.wetransform.eu/#/home">https://data.soilwise.wetransform.eu/#/home</a> (authorization needed)</p>
</div>
<h4 id="technical_components-metadata_validation-metadata-structure-validation">Metadata structure validation</h4>
<p>The initial steps of metadata validation comprise:</p>
<ol>
<li><strong>Syntax Check:</strong> Verifying that the metadata adheres to the specified syntax rules. This includes checking for allowed tags, correct data types, character encoding, and adherence to naming conventions.</li>
<li><strong>Schema (DTD/xsd/shacl/json-schema) Validation:</strong> Ensuring that the metadata conforms to the defined schema or metadata model. This involves verifying that all required elements are present, and relationships between different metadata components are correctly established.</li>
</ol>
<h4 id="technical_components-metadata_validation-metadata-completeness-indication">Metadata completeness indication</h4>
<p>The indication calculates a level of completeness of a record, indicated in % of 100 for endorsed properties of the EUSO soil profile, considering that some properties are conditional based on selected values in other properties.</p>
<h4 id="technical_components-metadata_validation-metadata-etsats-checking">Metadata ETS/ATS checking</h4>
<p>The methodology of ETS/ATS has been suggested to develop validation tests.</p>
<p><strong>Abstract Executable Test Suites (ATS)</strong> define a set of abstract test cases or scenarios that describe the expected behaviour of metadata without specifying the implementation details. These test suites focus on the logical aspects of metadata validation and provide a high-level view of metadata validation requirements, enabling stakeholders to understand validation objectives and constraints without getting bogged down in technical details. They serve as a valuable communication and documentation tool, facilitating collaboration between metadata producers, consumers, and validators. ATS are often documented using natural language descriptions, diagrams, or formal specifications. They outline the expected inputs, outputs, and behaviours of the metadata under various conditions.</p>
<p><strong>Executable Test Suites (ETS)</strong> are sets of tests designed according to ATS to perform the metadata validation. These tests are typically automated and can be run repeatedly to ensure consistent validation results. Executable test suites consist of scripts, programs, or software tools that perform various validation checks on metadata. These checks can include:</p>
<ol>
<li><strong>Data Integrity:</strong> Checking for inconsistencies or errors within the metadata. This includes identifying missing values, conflicting information, or data that does not align with predefined constraints.</li>
<li><strong>Standard Compliance:</strong> Assessing whether the metadata complies with relevant industry standards, such as Dublin Core, MARC, or specific domain standards like those for scientific data or library cataloguing.</li>
<li><strong>Interoperability:</strong> Evaluating the metadata's ability to interoperate with other systems or datasets. This involves ensuring that metadata elements are mapped correctly to facilitate data exchange and integration across different platforms.</li>
<li><strong>Versioning and Evolution:</strong> Considering the evolution of metadata over time and ensuring that the validation process accommodates versioning requirements. This may involve tracking changes, backward compatibility, and migration strategies.</li>
<li><strong>Quality Assurance:</strong> Assessing the overall quality of the metadata, including its accuracy, consistency, completeness, and relevance to the underlying data or information resources.</li>
<li><strong>Documentation:</strong> Documenting the validation process itself, including any errors encountered, corrective actions taken, and recommendations for improving metadata quality in the future.</li>
</ol>
<h4 id="technical_components-metadata_validation-technology-integration">Technology &amp; Integration</h4>
<p><a href="https://wetransform.to/haleconnect/" target="_blank">hale»connect</a> has been deployed. This platform includes the European Testing Framework ETF and can execute Metadata and Data validation usign the ETS approach outlined above. The User Guide is available <a href="https://help.wetransform.to/docs/getting-started/2018-04-28-quick-start" target="_blank">here</a>. The administration console of the platform can be accessed upon login at: <a href="https://data.soilwise.wetransform.eu/#/home">https://data.soilwise.wetransform.eu/#/home</a>.</p>
<p>The metadata validation component will show its full potential when integrated to (1) <a href="#technical_components-catalogue">SWR Catalogue</a>, (2) <a href="#technical_components-storage-storage-of-metadata">Storage of metadata</a>, and (3) Requires <a href="#technical_components-user_management-authentication">authentication</a> and <a href="#technical_components-user_management-authorisation">authorisation</a>.</p>
<h4 id="technical_components-metadata_validation-user-guide">User Guide</h4>
<p>When using the ‘Metadata only’ workflow, the metadata profile can be validated with hale»connect.
To do this, after logging into hale»connect, go directly to the setup of a new Theme (transformation project and Schema are therefore not required) and activate ‘Publish metadata only’ and specify where the metadata should come from. To validate the metadata file, upload the metadata and select ‘Metadata only’. Once validation is complete, a report can be called up.</p>
<p>A comprehensive tutorial video on setting up and executing transformation workflows can be found <a href="https://www.youtube.com/watch?v=U1lxzlUquE8&amp;list=PLoyBfgUelhNOwA_GGkd4hSwDnwNhxGC87&amp;index=3" target="_blank">here</a>.</p>
<h4 id="technical_components-metadata_validation-future-work">Future work</h4>
<ul>
<li>full development of the ETS, using populated codelists,</li>
<li>display validation results in the SoilWise Catalogue,</li>
<li>on-demand metadata validation, which would generate reports for user-uploaded metadata,</li>
<li>applicability of <a href="https://www.iso.org/standard/78900.html">ISO19157 Geographic Information – Data quality</a> (i.e. the standard intended for data validations) for metadata-based validation reports,</li>
<li><a href="https://www.w3.org/TR/shacl/" target="_blank">Shacl</a> is is in general intended for semantic web related validations; however, it's exact scope will be determined during the upcoming SoilWise developments. </li>
</ul>
<h3 id="technical_components-metadata_validation-link-liveliness-assessment">Link liveliness assessment</h3>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 0.1.0</p>
<p><strong>Projects:</strong> <a href="https://github.com/soilwise-he/link-liveliness-assessment">Link liveliness assessment</a></p>
</div>
<p>Metadata (and data and knowledge sources) tend to contain links to other resources. Not all of these URIs are persistent, so over time they can degrade. In practice, many non-persistent knowledge sources and assets exist that could be relevant for SWR, e.g. on project websites, in online databases, on the computers of researchers, etc. Links pointing to such assets might however be part of harvested metadata records or data and content that is stored in the SWR. </p>
<p>The link liveliness assessment subcomponent runs over the available links stored with the SWR assets and checks their status. The function is foreseen to run frequently over the URIs in the SWR repository, assessing and storing the status of the link. The link liveliness  privides the following functions:</p>
<ol>
<li><strong>OGC API Catalogue Integration</strong><ul>
<li>Designed to work specifically with <a href="https://ogcapi.ogc.org/records/" target="_blank">OGC API - Records</a> System</li>
<li>Extracts and evaluates URLs from catalogue items </li>
</ul>
</li>
<li><strong>Link Validation</strong><ul>
<li>Evaluates the validity of links to external sources and within the repository</li>
<li>Checks if metadata accurately represents the source</li>
</ul>
</li>
<li><strong>Support for OGC service links</strong><ul>
<li>Identifies and properly handles OGC service links (<a href="https://www.ogc.org/standard/wms/" target="_blank">WMS</a>, <a href="https://www.ogc.org/standard/wfs/" target="_blank">WFS</a>, <a href="https://www.ogc.org/standard/cat/" target="_blank">CSW</a>, <a href="https://www.ogc.org/standard/wcs/" target="_blank">WCS</a> etc.) before assessing them</li>
</ul>
</li>
<li><strong>Health Status Tracking</strong><ul>
<li>Provides up-to-date status history for every assessed link</li>
<li>Maintains a history of link health over time</li>
</ul>
</li>
<li><strong>Flexible Evaluation</strong><ul>
<li>Supports single resource evaluation on demand</li>
<li>Performs periodic tests to provide availability history</li>
</ul>
</li>
<li><strong>Broken link management</strong><ul>
<li>Identifies and categorizes broken links based on their status code ( <code>401 Unauthorized</code>, <code>404 Not Found</code>, <code>500 Server Error</code>)</li>
<li>Flags deprecated links after consecutive failed tests and excludes them from future check</li>
</ul>
</li>
<li><strong>Timeout management</strong><ul>
<li>Identifies resources exceeding specified timeout thresholds</li>
</ul>
</li>
</ol>
<p>A javascript widget is further used to display the link status directly in the <a href="#technical_components-catalogue">SWR Catalogue</a> record.</p>
<p><a class="glightbox" href="../_assets/images/link_liveliness.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Link liveliness indication" src="../_assets/images/link_liveliness.png" /></a></p>
<h4 id="technical_components-metadata_validation-technology">Technology</h4>
<ul>
<li><strong>Python</strong>
        Used for the linkchecker integration, API development, and database interactions</li>
<li><strong><a href="https://www.postgresql.org/" target="_blank">PostgreSQL</a></strong>
        Primary database for storing and managing link information</li>
<li><strong><a href="https://fastapi.tiangolo.com/" target="_blank">FastAPI</a></strong>
        Employed to create and expose REST API endpoints. 
        Utilizes FastAPI's efficiency and auto-generated <a href="https://swagger.io/docs/specification/2-0/what-is-swagger/" target="_blank">Swagger</a> documentation</li>
<li><strong>Docker</strong> 
        Used for containerizing the application, ensuring consistent deployment across environments</li>
<li><strong>CI/CD</strong>
        Automated pipeline for continuous integration and deployment, with scheduled weekly runs for link liveliness assessment</li>
</ul></section><section class="print-page" id="technical_components-metadata_authoring"><h1 id="technical_components-metadata_authoring-metadata-authoring">Metadata Authoring</h1>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Project:</strong> <a href="https://github.com/soilwise-he/soilinfohub">Soilinfohub</a></p>
<p><strong>Access point:</strong> <a href="https://github.com/soilwise-he/soilinfohub">https://github.com/soilwise-he/soilinfohub</a></p>
</div>
<h2 id="technical_components-metadata_authoring-functionality">Functionality</h2>
<p><strong>No implementations are yet an integrated part of the SWR delivery</strong>, as they were intentionally out of the first development itertation. Metadata authoring and generation is, however, possible using the hale»connect workflows.</p>
<h2 id="technical_components-metadata_authoring-foreseen-functionality">Foreseen functionality</h2>
<p>Users are enabled to create and maintain metadata records within the SWR, in case these records can not be imported from a remote source. Note that importing records from remote is the preferred approach from the SWR point of view because the ownership and persistence of the record is facilitated by the remote platform. </p>
<ul>
<li>Users login to the system and are enabled to upload a metadata record. </li>
<li>A form is available for users to create or manage an existing record. The form has select options for those fields which are linked to a codelist. </li>
<li>Users can also upload a spreadsheet of records which are converted to the MCF format.</li>
<li>Users will see metadata validation results.</li>
</ul>
<h2 id="technical_components-metadata_authoring-technology">Technology</h2>
<p>The authoring workflow uses a GIT backend, additions to the catalogue are entered by members of the GIT repository directly or via pull request (review).
Records are stored in <a href="https://www.iso.org/standard/32557.html">iso19139:2007</a> XML or MCF. <a href="https://geopython.github.io/pygeometa/reference/mcf/">MCF</a> is a subset of iso19139:2007 in a YAML encoding, defined by the pygeometa community. The <a href="https://geopython.github.io/pygeometa">pygeometa library</a> is used to 
convert the MCF to any requested metadata format.</p>
<p>The pygeometa community provides a <a href="https://osgeo.github.io/mdme" target="_blank">webbased form</a> for users uncomfortable with editing an MCF file directly. The tool can be hosted within SWR, to faciliate a dedicated color scheme. The form is auto generated from mcf json schema, the schema can be annotated to provide a dedicated EUSO user experience (for example preselect relevant codelists).</p>
<p>Users can also submit metadata using a CSV (excel) format, which is converted to MCF in a CI-CD workflow </p>
<p>At intervals the SWR ingests metadata which has been uploaded via the authoring workflow.</p></section><section class="print-page" id="technical_components-transformation"><h1 id="technical_components-transformation-transformation-and-harmonisation">Transformation and Harmonisation</h1>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 5.3</p>
<p><strong>Project:</strong> <a href="https://github.com/halestudio/hale">Hale Studio</a></p>
</div>
<p>These components make sure that data is interoperable, i.e. provided to agreed-upon formats, structures and semantics. They are used to ingest data and transform it into common standard data, e.g. in the central SWR format for soil.</p>
<p>The specific requirements these components have to fulfil are:</p>
<ul>
<li>The services shall be able to work with data that is described explicitly or implicitly with a schema. The services shall be able to load schemas expressed as XML Schemas, GML Application Schemas, RDF-S and JSON Schema.</li>
<li>The services shall support GML, GeoPackage, GeoJSON, CSV, RDF and XSL formats for data sources.</li>
<li>The services shall be able to connect with external download services such as WFS or OGC API, Features.</li>
<li>The services shall be able to write out data in GML, GeoPackage, GeoJSON, CSV, RDF and XSL formats.</li>
<li>There shall be an option to read and write data from relational databases.</li>
<li>The services should be exposed as <a href="https://ogcapi.ogc.org/processes/" target="_blank">OGC API Processes</a></li>
<li>Transformation processes shall include the following capabilities:<ul>
<li>Rename types &amp; attributes.</li>
<li>Convert between units of measurement.</li>
<li>Restructure data, e.g. through, joining, merging, splitting.</li>
<li>Map codelists and other coded values.</li>
<li>Harmonise observations as if they were measured using a common procedure using <a href="https://en.wikipedia.org/wiki/Pedotransfer_function" target="_blank">Pedotransfer Functions</a>.</li>
<li>Reproject data.</li>
<li>Change data from one format to another.</li>
</ul>
</li>
<li>There should be an interactive editor to create the specific transformation processes required for the SWR.</li>
<li>It should be possible to share transformation processes.</li>
<li>Transformation processes should be fully documented or self-documented.</li>
</ul>
<h2 id="technical_components-transformation-technology-integration">Technology &amp; Integration</h2>
<p>We have deployed the following components to the SWR infrastructure:</p>
<ul>
<li><a href="https://github.com/halestudio/hale/" target="_blank">hale studio</a>, a proven ETL tool optimised for working with complex structured data, such as XML, relational databases, or a wide range of tabular formats. It supports all required procedures for semantic and structural transformation. It can also handle reprojection. While Hale Studio exists as a multi-platform interactive application, its capabilities can be provided through a web service with an OpenAPI.</li>
<li>A comprehensive tutorial video on <a href="https://www.youtube.com/watch?v=U1lxzlUquE8&amp;list=PLoyBfgUelhNOwA_GGkd4hSwDnwNhxGC87&amp;index=3" target="_blank">soil data harmonisation with hale studio can be found here</a></li>
</ul>
<p>Another part of the deployed system, <a href="https://gdal.org/index.html" target="_blank">GDAL</a>, a very robust conversion library used in most FOSS and commercial GIS software, can be used for  a wealth of format conversions and can handle reprojection. In cases where no structural or semantic transformation is needed, a GDAL-based conversion service would make sense. </p>
<h3 id="technical_components-transformation-setting-up-a-transformation-process-in-haleconnect">Setting up a transformation process in hale»connect</h3>
<p>Complete the following steps to set up soil data transformation, validation and publication processes:</p>
<ol>
<li>Log into hale»connect.</li>
<li>Create a new transformation project (or upload it).</li>
<li>Specify source and target schemas.</li>
<li>Create a theme (this is a process that describes what  should happen with the data).</li>
<li>Add a new transformation configuration. Note: Metadata generation can be configured in this step.</li>
<li>A validation process can be set up to check against conformance classes.</li>
</ol>
<h3 id="technical_components-transformation-executing-a-transformation-process">Executing a transformation process</h3>
<ol>
<li>Create a new dataset and select the theme of the current source data, and provide the source data file.</li>
<li>Execute the transformation process. ETF validation processes are also performed. If successful, a target dataset and the validation reports will be created.</li>
<li>View and download services will be created if required.</li>
</ol>
<p>To create metadata (data set and service metadata), activate the corresponding button(s) when setting up the theme for the transformation process.</p></section><section class="print-page" id="technical_components-metadata_augmentation"><h1 id="technical_components-metadata_augmentation-metadata-augmentation">Metadata Augmentation</h1>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 0.1.0</p>
<p><strong>Project:</strong> <a href="https://github.com/soilwise-he/metadata-augmentation">Metadata augmentation</a></p>
</div>
<h2 id="technical_components-metadata_augmentation-functionality">Functionality</h2>
<p>In this component scripting / NLP / LLM are used on a metadata record to augment metadata statements about the resource. Augmentations are stored on a dedicated augmentation table, indicating the process which produced it.</p>
<table>
<thead>
<tr>
<th>metadata-uri</th>
<th>metadata-element</th>
<th>source</th>
<th>value</th>
<th>proces</th>
<th>date</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://geo.fi/data/ee44-aa22-33">https://geo.fi/data/ee44-aa22-33</a></td>
<td>spatial-scope</td>
<td>16.7,62.2,18,81.5</td>
<td><a href="https://inspire.ec.europa.eu/metadata-codelist/SpatialScope/national">https://inspire.ec.europa.eu/metadata-codelist/SpatialScope/national</a></td>
<td>spatial-scope-analyser</td>
<td>2024-07-04</td>
</tr>
<tr>
<td><a href="https://geo.fi/data/abc1-ba27-67">https://geo.fi/data/abc1-ba27-67</a></td>
<td>soil-thread</td>
<td>This dataset is used to evaluate Soil Compaction in Nuohous Sundström</td>
<td><a href="http://aims.fao.org/aos/agrovoc/c_7163">http://aims.fao.org/aos/agrovoc/c_7163</a></td>
<td>keyword-analyser</td>
<td>2024-06-28</td>
</tr>
</tbody>
</table>
<p>For the first SoilWise prototype, the functionality of the Metadata Augmentation component comprises:</p>
<ul>
<li><a href="#technical_components-metadata_augmentation-automatic-metadata-generation">Automatic metadata generation</a></li>
<li><a href="#technical_components-metadata_augmentation-translation-module">Translation module</a></li>
</ul>
<h3 id="technical_components-metadata_augmentation-automatic-metadata-generation">Automatic metadata generation</h3>
<p>To generate metadata (data set and service metadata), activate the corresponding button(s) when setting up the theme for the transformation process. The steps are described <a href="https://main.soilwise-documentation.pages.dev/technical_components/metadata_validation/#setting-up-a-transformation-process-in-haleconnect">here</a></p>
<h3 id="technical_components-metadata_augmentation-translation-module">Translation module</h3>
<p>Many records arrive in a local language, SWR translates the main properties for the record: title and abstract into English, to offer a single language user experience. The translations are used in filtering and display of records.</p>
<p>The translation module builds on the EU translation service (API documentation at <a href="https://language-tools.ec.europa.eu/">https://language-tools.ec.europa.eu/</a>). Translations are stored in a database for reuse by the SWR.
The EU translation returns asynchronous responses to translation requests, this means that translations may not yet be available after initial load of new data. A callback operation populates the database, from that moment a translation is available to SWR. The translation service uses 2-letter language codes, it means a translation from a 3-letter iso code (as used in for example iso19139:2007) to 2-letter code is required. The EU translation service has a limited set of translations from a certain to alternative language available, else returns an error.</p>
<p>Initial translation is triggered by a running harvester. The translations will then be available once the record is ingested to the triplestore and catalogue database in a followup step of the harvester. </p>
<h2 id="technical_components-metadata_augmentation-foreseen-functionality">Foreseen functionality</h2>
<p>In the next iterations, Metadata augmentation component is foreseen to include the following additional functions:</p>
<ul>
<li><a href="#technical_components-metadata_augmentation-keyword-matcher">Keyword matcher</a></li>
<li><a href="#technical_components-metadata_augmentation-spatial-locator">Spatial Locator</a></li>
<li><a href="#technical_components-metadata_augmentation-spatial-scope-analyser">Spatial scope analyser</a></li>
<li><a href="#technical_components-metadata_augmentation-euso-high-value-dataset-tagging">EUSO-high-value dataset tagging</a></li>
</ul>
<h3 id="technical_components-metadata_augmentation-keyword-matcher">Keyword matcher</h3>
<p>Keywords are an important mechanism to filter and cluster records. But similar keywords need to be equal to be able to match them. This module evaluates keywords of existing records to make them equal in case of high similarity. </p>
<p>Analyses existing keywords on a metadata record. Two cases can be identified:</p>
<ul>
<li>If a keyword, having a skos identifier, has a closeMatch or sameAs relation to a prefered keyword, the prefered keyword is used. </li>
<li>If an existing keyword, without skos identifier, matches a prefered keyword by (translated) string or synonym, then append the matched keyword (including skos identifier). Consider the risk of false positives.</li>
</ul>
<p>To facilitate this use case the SWR contains a knowledge graph of prefered keywords in the soil domain with relations to alternative keywords, such as agrovoc, gemet, dpedia, iso. This knowledge graph is maintained at <a href="https://github.com/soilwise-he/soil-health-knowledge-graph">https://github.com/soilwise-he/soil-health-knowledge-graph</a>. Agrovoc is multilingual, facilitating the translation case.</p>
<p>For metadata records which have not been analysed yet (in that iteration), the module extracts the records, for each keyword an analyses is made if it maches any of the prefered keywords, if so, the prefered keyword is added to the record. </p>
<h3 id="technical_components-metadata_augmentation-spatial-locator">Spatial Locator</h3>
<p>Analyses existing keywords to find a relevant geography for the record, it then uses the <a href="https://www.geonames.org/about.html" target="_blank">GeoNames</a> API to find spatial coordinates for the geography, which are inserted into the metadata record.</p>
<h3 id="technical_components-metadata_augmentation-spatial-scope-analyser">Spatial scope analyser</h3>
<p>A script that analyses the spatial scope of a resource</p>
<p>The bounding box is matched to country bounding boxes</p>
<p>To understand if the dataset has a global, continental, national or regional scope</p>
<ul>
<li>Retrieves all datasets (as iso19139 xml) from database (records table joined with augmentations) which:<ul>
<li>have a bounding box </li>
<li>no spatial scope</li>
<li>in iso19139 format</li>
</ul>
</li>
<li>For each record it compares the boundingbox to country bounding boxes: <ul>
<li>if bigger then continents &gt; global</li>
<li>If matches a continent &gt; continental</li>
<li>if matches a country &gt; national</li>
<li>if smaller &gt; regional</li>
</ul>
</li>
<li>result is written to as an augmentation in a dedicated table</li>
</ul>
<h3 id="technical_components-metadata_augmentation-euso-high-value-dataset-tagging">EUSO-high-value dataset tagging</h3>
<p>The EUSO high-value datasets are those with substantial potential to assess soil health status, as detailed on the <a href="https://esdac.jrc.ec.europa.eu/esdacviewer/euso-dashboard/" target="_blank">EUSO dashboard</a>. This framework includes the concept of <a href="https://esdac.jrc.ec.europa.eu/content/soil-degradation-indicators-eu" target="_blank">soil degradation indicator</a> metadata-based identification and tagging. Each dataset (possibly only those with the supra-national spatial scope - under discussion) will be annotated with a potential soil degradation indicator for which it might be utilised. Users can then filter these datasets according to their specific needs. </p>
<p>The EUSO soil degradation indicators employ specific <a href="https://esdac.jrc.ec.europa.eu/euso/euso-dashboard-sources" target="_blank">methodologies and thresholds</a> to determine soil health status, see also the Table below. These methodologies will also be considered, as they may have an impact on the defined thresholds. This issue will be examined in greater detail in the future.</p>
<table>
  <tr>
    <th>Soil Degradation</th>
    <th>Soil Indicator</th>
    <th>Type of methodic for threshold</th>
  </tr>
  <tr>
    <td rowspan="5" style="text-align: center; vertical-align: middle; font-weight: bold;">Soil erosion</td>
    <td>Water erosion</td>
    <td>RUSLE2015</td>
  </tr>
  <tr>
    <td>Wind erosion</td>
    <td>GIS-RWEQ</td>
  </tr>
  <tr>
    <td>Tillage erosion</td>
    <td>SEDEM</td>
  </tr>
  <tr>
    <td>Harvest erosion</td>
    <td>Textural index</td>
  </tr>
  <tr>
    <td>Post-fire recovery</td>
    <td>USLE (Type of RUSLE)</td>
  </tr>
  <tr>
    <td rowspan="5" style="text-align: center; vertical-align: middle; font-weight: bold;">Soil pollution</td>
    <td>Arsenic excess</td>
    <td>GAMLSS-RF</td>
  </tr>
  <tr>
    <td>Copper excess</td>
    <td>GLM and GPR</td>
  </tr>
  <tr>
    <td>Mercury excess</td>
    <td>LUCAS topsoil database</td>
  </tr>
  <tr>
    <td>Zinc Excess</td>
    <td>LUCAS topsoil database</td>
  </tr>
  <tr>
    <td>Cadmium Excess</td>
    <td>GEMAS</td>
  </tr>
  <tr>
    <td rowspan="3" style="text-align: center; vertical-align: middle; font-weight: bold;">Soil nutrients</td>
    <td>Nitrogen surplus</td>
    <td>NNB</td>
  </tr>
  <tr>
    <td>Phosphorus deficiency</td>
    <td>LUCAS topsoil database</td>
  </tr>
  <tr>
    <td>Phosphorus excess</td>
    <td>LUCAS topsoil database</td>
  </tr>
  <tr>
    <td style="text-align: center; vertical-align: middle; font-weight: bold;">Loss of soil organic carbon</td>
    <td>Distance to maximum SOC level</td>
    <td>qGAM</td>
  </tr>
  <tr>
    <td style="text-align: center; vertical-align: middle; font-weight: bold;">Loss of soil biodiversity</td>
    <td>Potential threat to biological functions</td>
    <td>Expert Polling, Questionnaire, Data Collection, Normalization and Analysis</td>
  </tr>
  <tr>
    <td style="text-align: center; vertical-align: middle; font-weight: bold;">Soil compaction</td>
    <td>Packing density</td>
    <td>Calculation of Packing Density (PD)</td>
  </tr>
  <tr>
    <td style="text-align: center; vertical-align: middle; font-weight: bold;">Salinization</td>
    <td>Secondary salinization</td>
    <td>-</td>
  </tr>
  <tr>
    <td style="text-align: center; vertical-align: middle; font-weight: bold;">Loss of organic soils</td>
    <td>Peatland degradation</td>
    <td>-</td>
  </tr>
  <tr>
    <td style="text-align: center; vertical-align: middle; font-weight: bold;">Soil consumption</td>
    <td>Soil sealing</td>
    <td>Raster remote sense data</td>
  </tr>
</table>

<p>Technically, we forsee the metadata tagging process as illustrated below. At first, metadata record's title, abstract and keywords will be checked for the occurence of specific <strong>values from the Soil Indicator and Soil Degradation Codelists</strong>, such as <code>Water erosion</code> or <code>Soil erosion</code> (see the Table above). If found, the <code>Soil Degradation Indicator Tag</code> (corresponding value from the Soil Degradation Codelist) will be displayed to indicate suitability of given dataset for soil indicator related analyses. Additionally, a search for corresponding <strong>methodology</strong> will be conducted to see if the dataset is compliant with the EUSO Soil Health indicators presented in the <a href="https://esdac.jrc.ec.europa.eu/esdacviewer/euso-dashboard/" target="_blank">EUSO Dashboard</a>. If found, the tag <code>EUSO High-value dataset</code> will be added. In later phase we assume search for references to Scientific Methodology papers in metadata record's links. Next, the possibility of involving a more complex search using soil thesauri will also be explored.</p>
<pre  class="mermaid"><code>flowchart TD
    subgraph ic[Indicators Search]
        ti([Title Check]) ~~~ ai([Abstract Check])
        ai ~~~ ki([Keywords Check])
    end
    subgraph Codelists
        sd ~~~ si
    end
    subgraph M[Methodologies Search]
        tiM([Title Check]) ~~~ aiM([Abstract Check])
        kl([Links check]) ~~~ kM([Keywords Check])
    end
    m[(Metadata Record)] --> ic
    m --> M
    ic-- + ---M
    sd[(Soil Degradation Codelist)] --> ic
    si[(Soil Indicator Codelist)] --> ic
    em[(EUSO Soil Methodologies list)] --> M
    M --> et{{EUSO High-Value Dataset Tag}}
    et --> m
    ic --> es{{Soil Degradation Indicator Tag}}
    es --> m
    th[(Thesauri)]-- synonyms ---Codelists
</code></pre></section><section class="print-page" id="technical_components-knowledge_graph"><h1 id="technical_components-knowledge_graph-knowledge-graph">Knowledge Graph</h1>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 0.1.0 </p>
<p><strong>Project:</strong> <a href="https://github.com/soilwise-he/soil-health-knowledge-graph">Soil Health Knowledge graph</a></p>
<p><strong>Access point:</strong> SWR SPARQL endpoint: <a href="https://sparql.soilwise-he.containers.wur.nl/sparql">https://sparql.soilwise-he.containers.wur.nl/sparql</a></p>
</div>
<p>SoilWise develops and implements a Knowledge Graph linking the knowledge captured in harvested and augmented metadata with various sources of internal and external knowledge sources, particularly taxonomies, vocabularies and ontologies that are also implemented as RDF graphs. Linking such graphs into a harmonized SWR Knowledge Graph allows reasoning over the relations in the stored graph, and thus allows connecting and smartly combining knowledge from those domains.</p>
<p>The first iteration of the SWR Knowledge Graph is a graph representation of the (harmonized) metadata that is currently harvested, validated and augmented as part of the SWR catalogue database. It's RDF representation, stored in a triple store, and the SPARQL endpoint deployed on top of the triple store, allow users alternate access to the metadata, exploiting semantics and relations between different assets. </p>
<p>At the same time, experiments have been performed to prepare for the linkage of this RDF metadata graph and existing and AI/ML generated graphs. In future iterations, the metadata graph will be linked/merged with a dedicated soil health knowledge graph also linking to external resources, establishing a broader interconnected soil health knowledge graph. Consequently, it will evolve into a knowledge network that allows much more powerful and impactful queries and reasoning, e.g. supporting decision support and natural language quering.</p>
<h2 id="technical_components-knowledge_graph-functionality">Functionality</h2>
<h3 id="technical_components-knowledge_graph-knowledge-graph-querying-sparql-endpoint">Knowledge Graph querying (SPARQL endpoint)</h3>
<p>The SPARQL endpoint, deployed on top of the SWR triple store, allows end users to query the SWR knowledge graph using the SPARQL query language. It is the primary access point to the <a href="#technical_components-storage-knowledge-graph-triple-store">knowledge graph</a>, both for humans, as well as for machines. Many applications and end users will instead interact with specialised assets that use the SPARQL end-point, such as the Chatbot or the API. However, the SPARQL end-point is the main source for the development of further knowledge applications and provides bespoke search to humans.</p>
<p>Since we're importing resources from various data and knowledge repositories, we expect many duplicities, blank nodes and conflicting statements. Implementation of rules should be permissive, not preventing inclusion, only flag potential inconsistencies.</p>
<h2 id="technical_components-knowledge_graph-ongoing-developments">Ongoing Developments</h2>
<h3 id="technical_components-knowledge_graph-knowledge-graph-enrichment-and-linking">Knowledge Graph enrichment and linking</h3>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Access point:</strong> <a href="https://voc.soilwise-he.containers.wur.nl/concept/">https://voc.soilwise-he.containers.wur.nl/concept/</a></p>
</div>
<p>As a preparation to extend the currently deployed metadata knowledge graph (KG) with broader domain knowledge, experimental work has been performed to enrich the KG to link it with other knowledge graphs. </p>
<p>The following aspects have been worked on and will  be furhter developed and integrated into future iterations of the SoilWise KG:</p>
<ul>
<li>Applying various methods using AI/ML to derive a (soil health) knowledge graph from unstructured content. This is piloted by using (parts of) the EEA report "Soil monitoring in Europe - Indicators and thresholds for soil quality assessments". It tests the effectiveness of various methods to generate knowledge in the form of KGs from documents, which could also benefit other AI/ML functions foreseen.</li>
<li>Establishing links between the SoilWise KG and external taxonomies and ontologies (linked data). Concepts in the SoilWise KG that (closely) match with concepts in the AGROVOC thesaurus are linked. The implemented method is exemplary for the foreseen wider linking required to establish a soil health KG.</li>
<li>Testing AI/ML based methods to derive additional knowledge (e.g. keywords, geography) for data and knowledge assets. Such methods could for instance be used to further augment metadata or fill exisiting metadata gaps. Besides testing such methods, this includes establishing a model that allows to distinguish between genuine and generated metadata.</li>
</ul>
<h2 id="technical_components-knowledge_graph-technology-integration">Technology &amp; Integration</h2>
<p>Components used:</p>
<ul>
<li>Virtuoso (version 07.20.3239)</li>
<li>Python notebooks</li>
</ul>
<p>Ontologies/Vocabularies/Schemas:</p>
<ul>
<li><a href="https://www.w3.org/2009/08/skos-reference/skos.html" target="_blank">SKOS Core</a></li>
<li><a href="https://www.dublincore.org/specifications/dublin-core/" target="_blank">Dublin Core</a></li>
<li><a href="https://aims.fao.org/aos/agrovoc" target="_blank">AGROVOC</a></li>
<li><a href="https://glosis-ld.github.io/glosis/" target="_blank">GloSIS</a></li>
<li><a href="https://aims.fao.org/aos/agrontology" target="_blank">Agrontology</a></li>
<li><a href="https://qudt.org/" target="_blank">QUDT</a></li>
</ul></section><section class="print-page" id="technical_components-natural_language_querying"><h1 id="technical_components-natural_language_querying-natural-language-querying">Natural Language Querying</h1>
<blockquote>
<p>Making open <strong><em>knowledge</em></strong> findable and accessible for SoilWise users</p>
</blockquote>
<div class="admonition component-header">
<p class="admonition-title">Info</p>
<p><strong>Current version:</strong> 0.1.0</p>
<p><strong>Project:</strong> <a href="https://github.com/soilwise-he/natural-language-querying">Natural Language querying</a></p>
</div>
<h2 id="technical_components-natural_language_querying-functionality">Functionality</h2>
<p>The aplication of Natural Language Querying (NLQ) for SoilWise and the integration into the SoilWise repository is currently still in the research phase. <strong>No implementations are yet an integrated part of the SWR delivery</strong>, in line with the plan for the first development iteration.</p>
<h2 id="technical_components-natural_language_querying-ongoing-developments">Ongoing Developments</h2>
<p>A strategy for development and implementation of NLQ to support SoilWise users is currently being developed. It considers various ways to make knowledge available through NLQ, possibly including options to migrate to different "levels" of complexity and innovation.</p>
<p>Such a "leveled approach" could start from leveraging existing/proven search technology (e.g. the Apache Solr open source search engine), and gradually combining this with new developments in NLP (such as transformer based language models) to make harvested knowledge metadata and harmonized knowledge graphs accessible to SoilWise users. </p>
<p>Typical general steps towards an AI-powered self-learning search system, are listed below from less to more complex. Note that to fully benefit from later steps it will be necessary to process knowledge (documents) themselves ("look inside the documents") instead of only working with the metadata about them. </p>
<ul>
<li>basic keyword based search (<strong>tf-idf</strong><sup id="fnref:4"><a class="footnote-ref" href="#technical_components-natural_language_querying-fn:4">4</a></sup>, <strong>bm25</strong><sup id="fnref:5"><a class="footnote-ref" href="#technical_components-natural_language_querying-fn:5">5</a></sup>)</li>
<li>use of taxonomies and entity extraction</li>
<li>understanding query intent (semantic query parsing, semantic knowledge graphs, virtual assistants)</li>
<li>automated relevance tuning (signals boosting, collaborative filtering, learning to rank)</li>
<li>Self-learning search system (full feedback loop using all user and content data)</li>
</ul>
<p><a class="glightbox" href="../_assets/images/search-cap-evolution.jpg" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Search capabilities evolution" src="../_assets/images/search-cap-evolution.jpg" /></a></p>
<p>Core topics are:</p>
<ul>
<li><strong>LLM</strong><sup id="fnref:1"><a class="footnote-ref" href="#technical_components-natural_language_querying-fn:1">1</a></sup> based (semantic) KG generation from unstructured content (leveraging existing search technology)</li>
<li>chatbot - Natural Language Interface (using advanced <strong>NLP</strong><sup id="fnref:2"><a class="footnote-ref" href="#technical_components-natural_language_querying-fn:2">2</a></sup> methodologies, such as LLMs)</li>
<li>LLM operationalisation (<strong>RAG</strong><sup id="fnref:3"><a class="footnote-ref" href="#technical_components-natural_language_querying-fn:3">3</a></sup> ingestion pipeline(s), generation pipeline, embedding store, models)</li>
</ul>
<p>The final aim is towards extractive question answering (extract answers from sources in real-time), result summarization (summarize search results for easy review), and abstractive question answering (generate answers to questions from search results). Not all these aims might be achievable within the project though. Later steps (marked in yellow in the following image) depend more on the use of complex language models.</p>
<p><a class="glightbox" href="../_assets/images/search-llm-cap.jpg" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Search LLM capabilities" src="../_assets/images/search-llm-cap.jpg" /></a></p>
<p>One step towards personalisation could be the use of (user) signals boosting and collaborative filtering. But this would require tracking and logging (user) actions.</p>
<p>A seperate development could be a chatbot based on selected key soil knowledge documents ingested into a vector database (as a fixed resource), or even a fine-tuned LLM that is more soil science specific than a plain foundation LLM.</p>
<p>Optionally the functionality can be extended from text processing to also include multi-modal data such as photos (e.g. of soil profiles). Effort needed for this has to be carefully considered.</p>
<p>Along the way natural language processing (NLP) methods and approaches can (and are) also be applied for various metadata handling and augmentation.</p>
<h2 id="technical_components-natural_language_querying-foreseen-technology">Foreseen technology</h2>
<ul>
<li>(Semantic) search engine, e.g. <a href="https://solr.apache.org">Apache Solr</a> or <a href="https://www.elastic.co/elasticsearch">Elasticsearch</a></li>
<li>Graph database (if needed)</li>
<li>(Scalable) vector database (if needed)</li>
<li>Java and/or Python based NLP libraries, e.g. <a href="https://opennlp.apache.org">OpenNLP</a>, <a href="https://spacy.io">spaCy</a></li>
<li>Small to large foundation LLMs</li>
<li>LLM development framework (such as <a href="https://www.langchain.com">langChain</a> or <a href="https://www.llamaindex.ai">LlamaIndex</a>)</li>
<li>Frontend toolkit </li>
<li>LLM deployment and/or hosted API access</li>
<li>Authentication and authorisation layer</li>
<li>Computation and storage infrastructure</li>
<li>Hardware acceleration, e.g. GPU (if needed)</li>
</ul>
<!-- previous text for reference:

LLM (and less complex Natural Language Processing (NLP) approaches) can be used to perform tasks in [metadata optimisation](#metadata-optimization) (e.g. identify similarities, resolve conflicts, populate gaps, classify or summarize resources). 

LLM can also power a chatbot interface in which a user asks questions to the bot on what type of resources they are looking for and the bot suggests options that can lead to improved search results (finding more relevant resources).

## Precondition

- [Prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering) and [Retrieval-Augmented Generation (RAG)](https://en.wikipedia.org/wiki/Prompt_engineering#Retrieval-augmented_generation) are approaches for preparing text to be used as input (prompt) for a generative AI model. These techniques help to tune the usually very generic foundational LLMs to generate more specific responses with less change of halucinations. RAG, in particular, should run post harvest, but pre inclusion into the knowledge graph (to prevent the full knowledge graph is analysed at every insert).
- [Embeddings](https://en.wikipedia.org/wiki/Word_embedding) are numerical (vector) representations of words, phrases, or larger text fragments (or even images) and have become a key part for text analysis. Small-size embeddings can be calculated on-the-fly, but larger size (capturing more complex semantic or linguistic characteristics), as used in RAG, take time to compute and thus are best stored. Vector databases are specifically being developed for this purpose, allowing fast processing and comparing of embeddings. No preferred vector database can be selected currently, as they are under active development, we'll experiment with a number of them and select the best suited.

## Metadata optimization

A component which uses NLP/LLM to improve metadata 

- identify similarities
    - very high similarity; indication that the record (despite the different identifier) is likely the same resource
    - high similarity; suggest it as a `similar` resource (linkage)
- resolve conflicts
    - if two records contain conflicting statements about a resource, try to derive from context which statement is correct
- populate gaps
    - if important properties are not populated (contact, title), try to derive it from context (with e.g. [Named-Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition))
- classify resources (add thematic keywords/tags)
    - Based on context, understand which thematic keywords/tags are relevant (soil threats, soil functions, soil health indicators). Keywords/tags should be related to provided codelist or can be suggested as a potential new one to be added.
- summarize resources
    - If a record lacks an abstract or has a too short abstract, ask LLM to derive an abstract from the resource itself 
- derive spatial or temporal extent from content
    - if no spatio-temporal extent is given, derive it from the resource itself or from context if possible

For each AI derived property, indicate that it has been derived by AI. (Need to be discussed how this can be indicated, e.g. with attributes / relations in the knowledge graphs?)

- Translate the Title, Abstract elements into English, French and German


## Empower a chatbot for user support in defining (and answering) a relevant catalogue question 

A chatbot is a natural language user interface to engage users in identifying what they are looking for and even provide a suggestion for an answer. Advanced LLMs provide improved text processing capabilities that can serve more usable human-machine interfaces.
-->

<!-- alternative text from former dashboard description
### Chatbot

[Large Language models](llm.md) (LLM) enriched with SoilWise content can offer an alternative interface to assist the user in finding and accessing the relevant knowledge or data source. Users interact with the chatbot interactively to define the relevant question and have it answered. The LLM will provide an answer but also provide references to sources on which the answer was based, in which the user can extend the search. The LLM can also support the user in gaining access to the source, using which software, for example.

-->

<div class="footnote">
<hr />
<ol>
<li id="technical_components-natural_language_querying-fn:1">
<p><strong>Large Language Model</strong>. Typically a deep learning model based on the transformer architecture that has been trained on vast amounts of text data, usually from known collections scraped from the Internet.&#160;<a class="footnote-backref" href="#technical_components-natural_language_querying-fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="technical_components-natural_language_querying-fn:2">
<p><strong>Natural Language Processing</strong>. An interdisciplinary subfield of computer science and artificial intelligence, primarily concerned with providing computers with the ability to process data encoded in natural language. It is closely related to information retrieval, knowledge representation and computational linguistics.&#160;<a class="footnote-backref" href="#technical_components-natural_language_querying-fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="technical_components-natural_language_querying-fn:3">
<p><strong>Retrieval Augmented Generation</strong>. A framework for retrieving facts from an external knowledge base to ground large language models on the most accurate, up-to-date information and enhancing the (pre)trained parameteric (semantic) knowledge with non-parameteric knowledge to avoid hallucinations and get better responses.&#160;<a class="footnote-backref" href="#technical_components-natural_language_querying-fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="technical_components-natural_language_querying-fn:4">
<p><strong>tf-idf</strong>. Term Frequency - Inverse Document Frequency, a statistical method in NLP and information retrieval that measures how important a term is within a document relative to a collection of documents (called a corpus).&#160;<a class="footnote-backref" href="#technical_components-natural_language_querying-fnref:4" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="technical_components-natural_language_querying-fn:5">
<p><strong>bm25</strong>. Okapi Best Match 25, a well-known ranking function used by search engines to estimate the relevance of documents to a given search query. It is based on tf-idf, but considered an improvement and adding some tunable parameters.&#160;<a class="footnote-backref" href="#technical_components-natural_language_querying-fnref:5" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
</ol>
</div></section><section class="print-page" id="technical_components-user_management"><h1 id="technical_components-user_management-user-management-and-access-control">User Management and Access Control</h1>
<p>User and organisation management, authorisation and authentication are complex, cross-cutting aspects of a system such as the SoilWise repository. Back-end and front-end components need to perform access control for authenticated users. Many organisations already have infrastructures in place, such as an Active Directory or a Single Sign On based on OAuth.</p>
<p><strong>No implementations are yet an integrated part of the SWR delivery</strong>, in line with the plan for the first development iteration.</p>
<p>The <strong>general model</strong> we apply is that:</p>
<ul>
<li>a user shall be a member of at least one organisation.</li>
<li>a user may have at least one role in every organisation that they are a member of.</li>
<li>a user always acts in the context of one of their roles in one organisation (similar to Github contexts).</li>
<li>organisations can be hierarchical, and user roles may be inherited from an organisation that is higher up in the hierarchy.</li>
</ul>
<p>The <strong>basic requirements</strong> for the SWR authentication mechanisms are:</p>
<ul>
<li>User authentication, and thus, provision of authentication tokens, shall be distributed ("Identity Brokering") and may happen through existing services. Authentication mechanisms that are to be supported include OAuth, SAML 2.0 and Active Directory.</li>
<li>An authoritative Identity Provider, such as an eIDAS-based one, should be integrated in a later iteration as well.</li>
<li>There shall be a central service that performs role and organisation mapping for authenticated users. This service also provides the ability to configure roles and set up organisations and users. This central service can also provide simple, direct user authentication (username/password-based) for those users who do not have their own authentication infrastructure.</li>
<li>There may be different levels of trust establishment based on the specific authentication service used. Higher levels of trust may be required to access critical data or infrastructure.</li>
<li>SWR services shall use <a href="https://www.keycloak.org/" target="_blank">Keycloak</a> or <a href="https://jwt.io/" target="_blank">JSON Web Tokens</a>  for authorization.</li>
<li>To access SWR APIs, the same rules apply as to access the SWR through the UI.</li>
</ul>
<p>In later iterations, the authentication and authorisation mechanisms should also be used to facilitate connector-based access to data space resources.</p>
<h2 id="technical_components-user_management-sign-up">Sign-up</h2>
<p>For every registered user of SWR components, an account is needed. This account can be created in one of three ways:</p>
<ol>
<li>Automatically, by providing an authentication token that was created by a trusted authentication service and that contains the necessary information on the organisation of the user and the intended role (this can e.g. be implemented through using a <a href="https://github.com/International-Data-Spaces-Association/IDS-G/blob/main/Components/IdentityProvider/DAPS/README.md" target="_blank">DAPS</a>)</li>
<li>Manually, through self-registration (may only be available for users from certain domains and/or for certain roles)</li>
<li>Through superuser registration; in this case the user gets issued an activation link and has to set the password to complete registration</li>
</ol>
<h2 id="technical_components-user_management-authentication">Authentication</h2>
<p>Certain functionalities of the SWR will be available to anonymous users, but functions that edit any of the state of the system (data, configuration, metadata) require an authenticated user. The easiest form of authentication is to use the login provided by the SWR itself. This log-in is username-password based. A second factor, e.g. through an authenticator app, may be added in the upcoming iteration.</p>
<p>Other forms of authentication include using an existing token.</p>
<h2 id="technical_components-user_management-authorisation">Authorisation</h2>
<p>Every component has to check whether an authenticated user may invoke a desired action based on that user's roles in their organisations. To ensure that the User Interface does not offer actions that a given user may not invoke, the user interface shall also perform authorisation.</p>
<p>Roles are generally defined using Privileges: A certain role may, for example, <code>read</code> certain resources, they may <code>edit</code> or even <code>delete</code> them. Here is an example of such a definition:</p>
<p>A standard <code>user</code> may only <code>read</code> and <code>edit</code> their own <code>User</code> profile, and read the information from their organisation. Once a user has been given the role <code>dataManager</code>, they may perform any CRUD operation on any <code>Data</code> that is in the scope of their <code>organisation</code>. They are also granted <code>read</code> access to publication <code>Theme</code> configurations on their own and in any parent organisations.</p>
<h2 id="technical_components-user_management-further-implementation-hints-and-technologies">Further implementation hints and Technologies</h2>
<p>The public cloud <a href="https://haleconnect.com/swagger/" target="_blank">hale connect user service</a> can be used for central user management.</p>
<h2 id="technical_components-user_management-completed-work-iteration-1">Completed work - Iteration 1</h2>
<ul>
<li>User/Role and Organisation management has been deployed and configured as part of weTransform's hale connect installation.</li>
<li>As of now, there are three Identity providers deployed as part of that infrastructure:<ul>
<li>The integrated user service in hale connect,</li>
<li>a Keycloak/OpenID-connect based one using GoPass via Github</li>
<li>a Data Spaces connector.</li>
</ul>
</li>
</ul>
<h2 id="technical_components-user_management-planned-work-iteration-2">Planned work - Iteration 2</h2>
<ul>
<li>Integrate eIDAS or a different autheoritative Identity Provider</li>
<li>Update other components to accept the tokens generated by this infrastructure</li>
</ul></section><h1 class='nav-section-title-end'>Ended: Technical Components</h1>
                        <h1 class='nav-section-title' id='section-apis'>
                            APIs <a class='headerlink' href='#section-apis' title='Permanent link'>↵</a>
                        </h1>
                        <section class="print-page" id="apis-apis-intro"><h1 id="apis-apis-intro-introduction">Introduction</h1>
<p>Within the first development iteration, the following APIs are employed in the SoilWise repository:</p>
<ul>
<li>Discovery APIs<ul>
<li><strong>SPARQL:</strong> <a href="https://sparql.soilwise-he.containers.wur.nl/sparql/">https://sparql.soilwise-he.containers.wur.nl/sparql/</a></li>
<li><strong>OGC API- Records:</strong> <a href="https://soilwise-he.containers.wur.nl/cat/openapi">https://soilwise-he.containers.wur.nl/cat/openapi</a></li>
<li><strong>Spatio Temporal Asset Catalog (STAC):</strong> <a href="https://soilwise-he.containers.wur.nl/cat/stac/openapi">https://soilwise-he.containers.wur.nl/cat/stac/openapi</a></li>
<li><strong>Catalog service for the Web (CSW):</strong> <a href="https://soilwise-he.containers.wur.nl/cat/openapi">https://soilwise-he.containers.wur.nl/cat/openapi</a></li>
<li><strong>Protocol for Metadata Harvesting (OAI-PMH):</strong> <a href="https://soilwise-he.containers.wur.nl/cat/oaipmh">https://soilwise-he.containers.wur.nl/cat/oaipmh</a></li>
<li><strong>OpenSearch:</strong> <a href="https://soilwise-he.containers.wur.nl/cat/opensearch">https://soilwise-he.containers.wur.nl/cat/opensearch</a></li>
</ul>
</li>
<li>Processing API's<ul>
<li><strong>Translate API:</strong> <a href="https://api.soilwise-he.containers.wur.nl/tolk/docs">https://api.soilwise-he.containers.wur.nl/tolk/docs</a></li>
<li><strong>Link Liveness Assessment API:</strong> <a href="https://api.soilwise-he.containers.wur.nl/linky/docs">https://api.soilwise-he.containers.wur.nl/linky/docs</a></li>
<li><strong>RDF to triplestore API:</strong> <a href="https://repo.soilwise-he.containers.wur.nl/swagger-ui/index.html">https://repo.soilwise-he.containers.wur.nl/swagger-ui/index.html</a></li>
</ul>
</li>
</ul>
<h2 id="apis-apis-intro-future-work">Future work</h2>
<p>SoilWise will in the future use more APIs to interact between components as well as enable remote users to interact with SoilWise components. Standardised APIs will be used if possible, such as:</p>
<ul>
<li><a href="https://www.openapis.org/" target="_blank">Open API</a></li>
<li><a href="https://graphql.com" target="_blank">GraphQL</a></li>
<li>OGC webservices (preferably <a href="https://ogcapi.ogc.org/" target="_blank">OGC API generation</a> based on Open API)</li>
<li><a href="https://www.w3.org/TR/sparql12-query/" target="_blank">SPARQL</a> for potential future knowledge graphs</li>
</ul></section><h1 class='nav-section-title-end'>Ended: APIs</h1>
                        <h1 class='nav-section-title' id='section-infrastructure'>
                            Infrastructure <a class='headerlink' href='#section-infrastructure' title='Permanent link'>↵</a>
                        </h1>
                        <section class="print-page" id="infrastructure-infrastructure-intro"><h1 id="infrastructure-infrastructure-intro-introduction">Introduction</h1>
<p>This section describes the general hardware infrastructure and deployment pipelines used for the SWR. As of the delivery of this initial version of the technical documentation, a prototype pipeline and hardware environment shall continuously be improved as required to fit the needs of the project.</p>
<p>For the development of <strong>First project iteration cycle</strong>, we defined the following criteria:</p>
<ul>
<li>There is no production environment.</li>
<li>There is a distributed staging environment, with each partner deploying their solutions to their specific hardware.</li>
<li>All of the hardware nodes used in the staging environment include an offsite backup capacity, such as a storage box, that is operated in a different physical location.</li>
<li>There is no central dev/test environment. Each organisation is responsible for its own dev/test environments.</li>
<li>The deployment and orchestration configuration for this iteration should be stored as YAML in a GitHub repository.</li>
<li>Deployments to the distributed staging environment are done preferably through GitHub Actions or through alternative pipelines, such as a Jenkins or GitLab instance provided by weTransform or other partners.</li>
<li>For each component, there shall be separate build processes managed by the responsible partners that result in the built images being made accessible through a hub (e.g. dockerhub)</li>
</ul>
<h2 id="infrastructure-infrastructure-intro-work-completed-iteration-1">Work completed - Iteration 1</h2>
<p>The Soilwise infrastructure uses components provided by Github. Github components are used to:</p>
<ul>
<li>Administer and assign to roles the different Soilwise users.</li>
<li>Register, prioritise and assign tasks.</li>
<li>Store source code of software artifacts.</li>
<li>Author documentation.</li>
<li>Run CI/CD pipelines.</li>
<li>Collect user feedback.</li>
</ul>
<p>During the iteration, the following components have been deployed:</p>
<p>on infrastructure provided by <strong>Wageningen University</strong>:</p>
<ul>
<li>A PostGreSQL database on the PostGreSQL cluster.</li>
<li>A number of repositories at the university Gitlab instance, including CI/CD pipelines to run metadata harvesters.</li>
<li>A range of services deployed on the univerity k8s cluster, with their configuration stored on Gitlab. Container images are stored on the university Harbor repository.</li>
<li>Usage logs monitored through the university instance of Splunk.</li>
<li>Availability monitoring provided by Uptimerobot.com.</li>
</ul>
<p>on <strong>WeTransform cloud infrastructure</strong>:</p>
<ul>
<li>a k8s deployment of the hale connect stack as been installed and configured. This instance can provide user management and has been integrated with the GitHub repository <a href="https://github.com/soilwise-he/Soilwise-credentials">https://github.com/soilwise-he/Soilwise-credentials</a>. The stack provides <a href="#technical_components-transformation">Transformation</a>, <a href="#technical_components-metadata_augmentation-automatic-metadata-generation">Metadata Generation</a> and <a href="#technical_components-metadata_validation">Validation</a> capabilities.</li>
</ul>
<h2 id="infrastructure-infrastructure-intro-future-work-iteration-2">Future work - Iteration 2</h2>
<p>The main objective of iteration 2 is to reorganise the orchestration of the different components, so all components can be centrally accessed and monitored.  </p>
<p>The integrations will, whereever feasible, build on API's which are standardised by W3C, OGC or de facto standards, such as Open API or GraphQL. </p>
<p>The intent of the consortium is to set up a distributed architecture, with the staging and production environment in an overall kubernetes-based orchestration mode if it is deemed necessary and advantageous at that point in time.</p></section><section class="print-page" id="infrastructure-containerization"><h1 id="infrastructure-containerization-containerization">Containerization</h1>
<p>The SWR is being developed in a containerised docker environment. This means that each software component, whether it's a database, storage system, or some kind of service, is compiled into a container image. These images are made available in a hub or repository, so that they can be deployed automatically whenever needed, including to fresh hardware.</p></section><section class="print-page" id="infrastructure-git"><h1 id="infrastructure-git-git-versioning-system">GIT versioning system</h1>
<p>All aspects of the SoilWise repository can be managed through the <a href="https://github.com/soilwise-he" target="_blank">SoilWise GitHub</a> repository. 
This allows all members of the Mission Soil and EUSO community to provide feedback or contribute to any of the aspects.</p>
<h2 id="infrastructure-git-documentation">Documentation</h2>
<p>Documentation is maintained in the markdown format using <a href="https://www.mkdocs.org/" target="_blank">McDocs</a> and deployed as html or pdf using GitHub Pages.</p>
<p>An interactive preview of architecture diagrams is also maintained and published using GitHub Pages.</p>
<h2 id="infrastructure-git-source-code">Source code</h2>
<p>Software libraries tailored or developed in the scope of SoilWise are maintained through the GitHub repository.</p>
<h2 id="infrastructure-git-container-build-scriptsdeployments">Container build scripts/deployments</h2>
<p>SoilWise is based on an orchestrated set of container deployments. Both the definitions of the containers as well as the orchestration of those containers are maintained through Git.</p>
<h2 id="infrastructure-git-harvester-definitions">Harvester definitions</h2>
<p>The configuration of the endpoint to be harvested, filters to apply and the interval is stored in a GitHub repository. If the process runs as a CI-CD pipeline, then the logs of each run are also available in Git.</p>
<h2 id="infrastructure-git-authored-and-harvested-metadata">Authored and harvested metadata</h2>
<p>Metadata created in SWR, as well as metadata imported from external sources, are stored in GitHub, so a full history of each record is available, and users can suggest changes to existing metadata.</p>
<h2 id="infrastructure-git-validation-rules">Validation rules</h2>
<p>Rules (ATS/ETS) applied to metadata (and data) validation are stored in a git repository.</p>
<h2 id="infrastructure-git-etl-configuration">ETL configuration</h2>
<p>Alignments to be applied to the source to be standardised and/or harmonised are stored on a git repository, so users can try the alignment locally or contribute to its development.</p>
<h2 id="infrastructure-git-backlog-discussions">Backlog / discussions</h2>
<p>Roadmap discussion, backlog and issue management are part of the GitHub repository. Users can flag issues on existing components, documentation or data, which can then be followed up by the participants.</p>
<h2 id="infrastructure-git-release-management">Release management</h2>
<p>Releases of the components and infrastructure are managed from a GitHub repository, so users understand the status of a version and can download the packages. The release process is managed in an automated way through CI-CD pipelines.</p></section><h1 class='nav-section-title-end'>Ended: Infrastructure</h1><section class="print-page" id="glossary"><h1 id="glossary-glossary">Glossary</h1>
<dl>
<dt>
	<a id="541072196057595c85c7fae3839fa2ec">Abstracting and indexing service</a> 
</dt>
<dd>Abstracting and indexing service is a service, e.g. a search engine, that abstracts and indexes digital objects or metadata records, and provides matching and ranking functionality in support of information retrieval.</dd>

<dt>
	<a id="6cc9656fdb5357ce2c276b49dbde5068">Acceptance Criteria</a> 
</dt>
<dd>Acceptance Criteria can be used to judge if the resulting software satisfies the user's needs. A single user story/requirement can have multiple acceptance criteria.</dd>

<dt>
	<a id="22db89581528db2e1e2e21fa34749c28">API</a> 
</dt>
<dd>Application programming interface (API) is a way for two or more computer programs to communicate with each other (source <a href="https://en.wikipedia.org/wiki/API" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="33d881a2a34b64d533254d698e7bf622">Application profile</a> 
</dt>
<dd>Application profile is a specification for data exchange for applications that fulfil a certain use case. In addition to shared semantics, it also allows for the imposition of additional restrictions, such as the definition of cardinalities or the use of certain code lists (source: <a href="https://purl.eu" target="_blank">purl.eu</a>).</dd>

<dt>
	<a id="f0295b89833aebad883aec8befddb616">Artificial Intelligence</a> 
</dt>
<dd>Artificial Intelligence (AI) is a field of study that develops and studies intelligent machines. It includes the fields rule based reasoning, machine learning and natural language processing (NLP). (source: <a href="https://en.wikipedia.org/wiki/Artificial_intelligence" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="60c3a65455d5b8fd9b5dc6dc525b5822">Assimilation</a> 
</dt>
<dd>Assimilation is a term indicating the processes involved to combine multiple datasets with different origin into a common dataset, the term is somewhat similarly used in psychology as <code>incorporation of new concepts into existing schemes</code> (source: <a href="https://en.wikipedia.org/wiki/Assimilation" target="_blank">wikipedia</a>). But is not well aligned with its usage in the data science community: <code>updating a numerical model with observed data</code> (source: <a href="https://en.wikipedia.org/wiki/Assimilation" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="9b8bedf06593ff74dabab91e429007a7">ATOM</a> 
</dt>
<dd>ATOM is a standardised interface to exchange news feeds over the internet. It has been adopted by INSPIRE as a basic alternative to download services via WFS or WCS.</dd>

<dt>
	<a id="77f1540f4e3ae057b1bdce1cd2208be9">Catalogue</a> 
</dt>
<dd>Catalogue or <em>metadata registry</em> is a central location in an organization where metadata definitions are stored and maintained (source: <a href="https://en.wikipedia.org/wiki/Metadata_registry" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="9fdad3561c8911058a191c6a7835d266">Code list</a> 
</dt>
<dd>Code list an enumeration of terms in order to constrain input and avoid errors (source: <a href="https://tfig.unece.org/contents/code-lists.htm" target="_blank">UN</a>).</dd>

<dt>
	<a id="509c7ef55fc77d9b8e09e3b191219a36">Conceptual model</a> 
</dt>
<dd>Conceptual model or <em>domain model</em> represents concepts (entities) and relationships between them (source: <a href="https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="84bc9f1fc801ceab8ec80bdbae2c0585">Content negotiation</a> 
</dt>
<dd>Content negotiation refers to mechanisms that make it possible to serve different representations of a resource at the same URI (source: <a href="https://en.wikipedia.org/wiki/Content_negotiation" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="e0161bf39a8c98c1995c5089e72e6398">Controlled vocabulary</a> 
</dt>
<dd>Controlled vocabulary provides a way to organize knowledge for subsequent retrieval. A carefully selected list of words and phrases, which are used to tag units of information so that they are more easily retrieved by a search (source: <a href="https://semwebtec.wordpress.com/2010/11/23/contolled-vocabulary-vs-ontology" target="_blank">Semwebtech</a>). Vocabulary, unlike the dictionary and thesaurus, offers an in-depth analysis of a word and its usage in different contexts (source: <a href="https://www.learngrammar.net/a/vocabulary-dictionary-thesaurus" target="_blank">learn grammar</a>)</dd>

<dt>
	<a id="718be74414a3732d35fe52bec2727dee">Cordis</a> 
</dt>
<dd>Cordis is the primary source of <a href="https://cordis.europa.eu/" target="_blank">results from EU-funded projects</a> since 1990</dd>

<dt>
	<a id="694d0aebdff2535dc12d4a6a49213457">Corpus</a> 
</dt>
<dd>Corpus (plural: Corpora) is a repository of text documents (knowledge resources); a body of works. Typically the input for information retrieval.</dd>

<dt>
	<a id="968ae8d24ac4964c08d435383e13f858">CSW</a> 
</dt>
<dd><a href="https://www.ogc.org/standard/csw" target="_blank">CSW</a> Catalogue Service for the Web</dd>

<dt>
	<a id="3dc1b522de5f3e63019ffea1560008b0">Data</a> 
</dt>
<dd>Data is a collection of discrete or continuous values that convey information, describing the quantity, quality, fact, statistics, other basic units of meaning, or simply sequences of symbols that may be further interpreted formally (<a href="https://en.wikipedia.org/wiki/Data">Wikipedia</a>).</dd>

<dt>
	<a id="40fc32afebeb8a99e1f5d738a12c8be4">Data source</a> 
</dt>
<dd>Data source/provider is a provider of data resources.</dd>

<dt>
	<a id="e9e3de8d04ac2703f34788e8000305c5">Data management</a> 
</dt>
<dd>Data management is the practice of collecting, organising, managing, and accessing data (for some purpose, such as decision-making).</dd>

<dt>
	<a id="a8fbb825fdb4195708a188195cfedd6b">Dataset</a> 
</dt>
<dd>Dataset (Also: Data set) A collection of data (<a href="https://en.wikipedia.org/wiki/Data_set">Wikipedia</a>).</dd>

<dt>
	<a id="756ea0b3600668feb751bf2e9587b970">Dataverse</a> 
</dt>
<dd><a href="https://dataverse.org/" target="_blank">Dataverse</a> is open source research data repository software</dd>

<dt>
	<a id="a093ca337c50be8c780b1279ab2c8777">Datacite</a> 
</dt>
<dd><a href="https://datacite.org/" target="_blank">Datacite</a> is a non-profit organisation that provides persistent identifiers (DOIs) for research data.</dd>

<dt>
	<a id="5c481e845cf1fa24f849e90899875029">Datacite metadata scheme</a> 
</dt>
<dd><a href="https://schema.datacite.org/" target="_blank">Datacite metadata schema</a> a datamodel for metadata for scientific resources</dd>

<dt>
	<a id="9c9b8bf2faf91322c597b53bc167ab21">Digital exchange of soil-related data</a> 
</dt>
<dd>Digital exchange of soil-related data (ISO 28258:2013) presents a conceptual model of a common understanding of what soil profile data are</dd>

<dt>
	<a id="690592265987bdd619c8e795fae1bd9a">Digital soil mapping</a> 
</dt>
<dd>Digital soil mapping is the creation and the population of a geographically referenced soil databases generated at a given resolution by using field and laboratory observation methods coupled with environmental data through quantitative relationships (source: <a href="https://en.wikipedia.org/wiki/Digital_soil_mapping" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="cdef7dfe51db9fb683a42e34b20c99d8">Discovery service</a> 
</dt>
<dd>Discovery service is a concept from <a href="https://inspire.ec.europa.eu/metadata-codelist/SpatialDataServiceType/discovery" target="_blank">INSPIRE</a> indicating a service type which enables discovery of resources (search and find). Typically implemented as CSW.</dd>

<dt>
	<a id="7fd2f79de52452afff0bf7d4da852c18">Download service</a> 
</dt>
<dd>Download service is a concept from <a href="https://inspire.ec.europa.eu/metadata-codelist/SpatialDataServiceType/download" target="_blank">INSPIRE</a> indicating a service type which enables download of a (subset of a) dataset. Typically implemented as WFS, WCS, SOS or Atom.</dd>

<dt>
	<a id="31307bdd5120aae20796bdf2f732ce70">DOI</a> 
</dt>
<dd><a href="https://www.doi.org/" target="_blank">DOI</a> a digital identifier of an object, any object — physical, digital, or abstract</dd>

<dt>
	<a id="e18efac0277ce77b52173859d418480f">Encoding</a> 
</dt>
<dd>Encoding is the format used to <a href="https://en.wikipedia.org/wiki/Serialization" target="_blank">serialise</a> a resource to a file, common encodings are xml, json, turtle</dd>

<dt>
	<a id="b7c1ba65150be6ebb5f93dcad14969c7">ESDAC</a> 
</dt>
<dd><a href="https://esdac.jrc.ec.europa.eu/" target="_blank">ESDAC</a> thematic centre for soil related data in Europe</dd>

<dt>
	<a id="7fcfafaae765822e7a0f44cc9875117b">EUSO</a> 
</dt>
<dd><a href="https://joint-research-centre.ec.europa.eu/eu-soil-observatory-euso_en" target="_blank">EUSO</a> European Soil Observatory</dd>

<dt>
	<a id="df6e91837240ea70801153b02a74b424">GDAL OGR</a> 
</dt>
<dd><a href="https://gdal.org" target="_blank">GDAL and OGR</a> are software packages widely used to interact with a variety of spatial data formats</dd>

<dt>
	<a id="76558efa4e244fe6b671d5b866d7fb4f">GML</a> 
</dt>
<dd>Geography Markup Language (GML) is an xml based standardised encoding for spatial data.</dd>

<dt>
	<a id="8ed7fc01cc2914404a45bf647bfad17a">GeoPackage</a> 
</dt>
<dd><a href="https://www.ogc.org/standard/geopackage/" target="_blank">GeoPackage</a> a set of conventions for storing spatial data a <a href="https://www.sqlite.org/" target="_blank">SQLite</a> database</dd>

<dt>
	<a id="c90ab04bc4dbd2261040d791db26dcbc">Geoserver</a> 
</dt>
<dd><a href="https://geoserver.org" target="_blank">Geoserver</a> java based software package providing access to remote data through OGC services</dd>

<dt>
	<a id="50b7033593f401513fe2aa5af1cc2c28">Global Soil Information System</a> 
</dt>
<dd>Global Soil Information System (<a href="https://www.fao.org/global-soil-partnership/areas-of-work/soil-information-and-data/en/" target="_blank">GLOSIS</a>) is an activity of FAO Global Soil Partnership enabling a federation of soil information systems and interoperable data sets </dd>

<dt>
	<a id="921f5fcc52c6d8f065d7e0bcd578b599">GLOSIS domain model</a> 
</dt>
<dd>GLOSIS domain model is an abstract, architectural component that defines how data are organised; it embodies a common understanding of what soil profile data are.</dd>

<dt>
	<a id="44666ffedaf3db3962afce720319778c">GLOSIS Web Ontology</a> 
</dt>
<dd><a href="https://github.com/rapw3k/glosis" target="_blank">GLOSIS Web Ontology</a> is an implementation of the GLOSIS domain model using semantic technology</dd>

<dt>
	<a id="424026cbf385a6c83e107f711bd0a532">GLOSIS Codelists</a> 
</dt>
<dd><a href="https://github.com/rapw3k/glosis/blob/master/glosis_cl.ttl" target="_blank">GLOSIS Codelists</a> is a series of codelists supporting the GLOSIS web ontology. Including the codelists as published in the FAO Guidelines for Soil Description (v2007), soil properties as collected by FAO GfSD and procedures as initally collected by Johan Leenaars.</dd>

<dt>
	<a id="9a563fa79476b240c977cf16268e9857">Glosolan</a> 
</dt>
<dd><a href="https://www.fao.org/global-soil-partnership/glosolan" target="_blank">Glosolan</a> network to strengthen the capacity of laboratories in soil analysis and to respond to the need for harmonizing soil analytical data</dd>

<dt>
	<a id="838382aa629f736d09fb595074f3e202">HALE</a> 
</dt>
<dd><a href="https://github.com/halestudio/hale" target="_blank">Humboldt Alignment Editor</a> (HALE) java based desktop software to compose and apply a data transformation to data</dd>

<dt>
	<a id="7c5557f5be179edf81d7a66d5eed7cd8">Harmonization</a> 
</dt>
<dd>Harmonization is the process of transforming two datasets to a common model, a common projection, usage of common domain values and align their geometries</dd>

<dt>
	<a id="37202c7ff879fa4ad4fa15c46ae0e2a2">Information retreival</a> 
</dt>
<dd>Information retreival (IR) is the task of identifying and retrieving information system resources (e.g. digital objects or metadata records) that are relevant to a search query. It includes searching for the information in a document, searching for the documents themselves, as well as searching for metadata describing the documents.</dd>

<dt>
	<a id="aa61d380cf28c10954d2adf65e64a6ba">Iteration</a> 
</dt>
<dd>An iteration is each development cycle (three foreseen within the SoilWise project) in the project. Each iteration can have phases. There are four phases per iteration focussing on co-design, development, integration and validation, demonstration.</dd>

<dt>
	<a id="fc88cacce54cd3b638ddcdf7ded0f58d">JRC</a> 
</dt>
<dd>JRC Joint Research Centre of the European Commission, its Directorate General. The JRC provides independent, evidence-based science and knowledge, supporting EU policies to positively impact society. Relevant policy areas within JRC are <a href="https://joint-research-centre.ec.europa.eu/scientific-activities-z/soil_en" target="_blank">JRC Soil</a> and <a href="https://inspire.ec.europa.eu/whos-who-inspire/57734" target="_blank">JRC INSPIRE</a></dd>

<dt>
	<a id="8b8c5faa16987968f12124ee8f219b95">Knowledge</a> 
</dt>
<dd><p>Knowledge is facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject. SoilWise mainly considers explicit knowledge -- Information that is easily articulated, codified, stored, and accessed. E.g. via books, web sites, or databases. It does not include implicit knowledge (information transferable via skills) nor tacit knowledge (gained via personal experiences and individual contexts). Explicit knowledge can be further divided into semantic and structural knowledge.</p>
<ul>
<li><strong>Semantic knowledge:</strong> Also known as declarative knowledge, refers to knowledge about facts, meanings, concepts, and relationships. It is the understanding of the world around us, conveyed through language. Semantic knowledge answers the "What?" question about facts and concepts.</li>
<li><strong>Structural knowledge:</strong> Knowledge about the organisation and interrelationships among pieces of information. It is about understanding how different pieces of information are interconnected. Structural knowledge explains the "How?" and "Why?" regarding the organisation and relationships among facts and concepts.</li>
</ul>
</dd>

<dt>
	<a id="e746dc10475c6e523c49945e0607d21a">Knowledge graph</a> 
</dt>
<dd>Knowledge graph is a representation of a network of real-world entities -- such as objects, events, situations or concepts -- and the relationships between them. Typically the network is made up of nodes, edges, and labels. Both semantic and structural knowledge can be expressed, stored, searched, visualised, and explored as knowledge graphs.</dd>

<dt>
	<a id="3e5be7d60ad76322d2450aaad80f6f66">Knowledge resource</a> 
</dt>
<dd>Knowledge resource is a digital object, such as a document, a web page, or a database, that holds relevant explicit knowledge.</dd>

<dt>
	<a id="20037e3414e8d881bbab5095298c65af">Knowledge source</a> 
</dt>
<dd>Knowledge source/provider is a provider of knowledge resources.</dd>

<dt>
	<a id="5b73d115ec3d3565c3c657a2a2f44539">Knowledge management</a> 
</dt>
<dd>Knowledge managmenet is the practice of collecting, organising, managing, and accessing knowledge (for some purpose, such as as decision-making).</dd>

<dt>
	<a id="8fb8d3e066d97b6f7772811fc8c5fa88">LLM</a> 
</dt>
<dd>Large Language Model is typically a deep learning model based on the transformer architecture that has been trained on vast amounts of text data, usually from know collections scraped from the Internet.</dd>

<dt>
	<a id="0e95864e370b4031bf8b9c7a8f542e74">Mapserver</a> 
</dt>
<dd><a href="https://mapserver.org" target="_blank">Mapserver</a> C based software package providing access to remote data through OGC services</dd>

<dt>
	<a id="724ec637e8c53f4836544068db4ba4c2">Metadata</a> 
</dt>
<dd>(Descriptive) metadata is a summary information describing digital objects such as datasets and knowledge resources.</dd>

<dt>
	<a id="1b26fb938f96003982337124bf61e028">Metadata record</a> 
</dt>
<dd>Metadata record is an entry in e.g. a catalogue or abstracting and indexing service with summary information about a digital object.</dd>

<dt>
	<a id="c94267b4563ae109aa0a8adb3352cd11">Metadata source</a> 
</dt>
<dd>Metadata source/provider is a provider of metadata.</dd>

<dt>
	<a id="a07d40280ecd997513f855d661dbd930">NLP</a> 
</dt>
<dd>Natural Language Processing is an interdisciplinary subfield of computer science and artificial intelligence, primarily concerned with providing computers with the ability to process data encoded in natural language. It is closely related to information retrieval, knowledge representation and computational linguistics.</dd>

<dt>
	<a id="5e835942810d65af05e3b9eff31a6fa7">Observations and Measurements</a> 
</dt>
<dd>A conceptual model for <a href="https://www.ogc.org/standard/om/" target="_blank">Observations and Measurements</a> (O&amp;M), also known as ISO19156</dd>

<dt>
	<a id="8a1f66b23623e2f592a681204a912923">OGC API</a> 
</dt>
<dd><a href="https://ogcapi.ogc.org/" target="_blank">OGC API</a> building blocks that can be used to assemble novel APIs for web access to geospatial content</dd>

<dt>
	<a id="46b975d5bf5040d04ec2c210fe14d3c8">Ontology</a> 
</dt>
<dd>Ontology is a formal representation of the entities in a knowledge graph. Ontologies and knowledge graphs can be expressed in a similar manner and they are closely related. Ontologies can be seen as the (semantic) data model defining classes, relationships and attributes, while knowledge graphs contain the real data according to the (semantic) data model.</dd>

<dt>
	<a id="f29c63a9476d61598239b7926a6571f2">Persistent identifier</a> 
</dt>
<dd>Persistent identifier is a long-lasting reference to a digital object.</dd>

<dt>
	<a id="1c698c4d6cf870156aafa8c48af8ca2f">Product backlog</a> 
</dt>
<dd>Product backlog is the document where user stories/requirements are gathered with their acceptance criteria, and prioritized.</dd>

<dt>
	<a id="d586c1d45b056ca6532be9a1e3c94214">QGIS</a> 
</dt>
<dd><a href="https://qgis.org" target="_blank">QGIS</a> desktop software package to create spatial vizualisations of various types of data</dd>

<dt>
	<a id="db9ec7ec03e11e80e5cf03c27e644c94">RAG</a> 
</dt>
<dd>Retrieval Augmented Generation is a framework for retrieving facts from an external knowledge base to ground large language models on the most accurate, up-to-date information and enhancing the (pre)trained parameteric (semantic) knowledge with non-parameteric knowledge to avoid hallucinations and get better responses.</dd>

<dt>
	<a id="f97b879efc4adc76b604d1673604731d">REA</a> 
</dt>
<dd>REA is the European Research Executive Agency, it's mandate is to manage several EU programmes and support services.</dd>

<dt>
	<a id="ef4068299e969e9bb67625b37ac05d73">Relational model</a> 
</dt>
<dd>Relational model an approach to managing data using a structure and language consistent with first-order predicate logic (source: <a href="https://en.wikipedia.org/wiki/Relational_model" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="6b2d51cbc169e0680ac30b7acf78580a">RDF</a> 
</dt>
<dd><a href="https://www.w3.org/RDF/" target="_blank">Resource Description Framework</a> (RDF) a standard model for data interchange on the Web</dd>

<dt>
	<a id="d6d1c1550213b43a9fe680c9a760c36e">Representational state transfer</a> 
</dt>
<dd>Representational state transfer (REST) a set of guidelines for creating stateless, reliable web APIs (source: <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="3c29f133ee25546741abe3d8e7623edb">Requirements</a> 
</dt>
<dd>Requirements are the capabilities of an envisioned component of the repository which are classified as ‘must have’, or ‘nice to have’.</dd>

<dt>
	<a id="109c84944ce718dd2f4b94b38a78f6e6">Rolling plan</a> 
</dt>
<dd>Rolling plan is a methodology for considering the internal and external developments that may generate changes to the SoilWise Repository design and development. It keeps track of any developments and changes on a technical, stakeholder group level or at EUSO/JRC.</dd>

<dt>
	<a id="84e9d424372824a086d4a21a97669bd0">SensorThings API</a> 
</dt>
<dd><a href="https://www.ogc.org/standard/sensorthings/" target="_blank">SensorThingsAPI</a> (STA) is a formalised protocol to exchange sensor data and tasks between IoT devices, maintained at Open Geospatial Consortium.</dd>

<dt>
	<a id="124883c148e311d7ee7866d87886a9bc">Sensor Observation Service</a> 
</dt>
<dd><a href="https://www.ogc.org/standard/sos/" target="_blank">Sensor Observation Service</a> (SOS) is a formalised protocol to exchange sensor data between entities, maintained at Open Geospatial Consortium.</dd>

<dt>
	<a id="61ac9724c01b204d37870ffce20eec1d">Sprint</a> 
</dt>
<dd>Sprint is a small timeframe during which tasks have been defined.</dd>

<dt>
	<a id="3e30ba71b0e1cb2ca3af3f938e58cf88">Sprint backlog</a> 
</dt>
<dd>Sprint backlog is composed of the set of product backlog elements chosen for the sprint, and an action plan for achieving them.</dd>

<dt>
	<a id="c305b5f76c51f6c396db4bd6042d0e77">Soil classification</a> 
</dt>
<dd>Soil classification deals with the systematic categorization of soils based on distinguishing characteristics as well as criteria that dictate choices in use (source: <a href="https://en.wikipedia.org/wiki/Soil_classification" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="83b8ea6ae03f2d03459b19c27cec2c47">Soilgrids</a> 
</dt>
<dd><a href="https://www.isric.org/explore/soilgrids" target="_blank">Soilgrids</a> a system for global digital soil mapping that uses many profile data and machine learning methods to predict the spatial distribution of soil properties across the globe</dd>

<dt>
	<a id="e52887bc8609f375464335e21a6a80e1"> SoilWise Use cases</a> 
</dt>
<dd>The SoilWise use cases are described in the Grant Agreement to understand the needs from the stakeholder groups (users). Each use case provides user stories epics.</dd>

<dt>
	<a id="1fa264c111590ce82ef8aad4dc07ab9e">Task</a> 
</dt>
<dd>Task is the smallest segment of work that must be done to complete a user story/requirement.</dd>

<dt>
	<a id="b087d77c5111da2f586234f19054c6f6">UML</a> 
</dt>
<dd>Unified Modeling Language (UML) a general-purpose modeling language that is intended to provide a standard way to visualize the design of a system (source: <a href="https://en.wikipedia.org/wiki/Unified_Modeling_Language" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="2eca2db1975c6aeccc2eb951101ade7e"> Usage scenarios</a> 
</dt>
<dd>Usage scenarios describe how (groups of) users might use the software product. These usage scenarios can originate or be updated from the SoilWise use cases, user story epic or user stories/requirements.</dd>

<dt>
	<a id="c55b32cbdd994eadd3c8bfa066cc74b9">User story</a> 
</dt>
<dd>A User story is a statement, written from the point of view of the user, that describes the functionality needed by the user from the SoilWise Repository. </dd>

<dt>
	<a id="ab15a8b55a5cbf769b61345627297d28">User story epic</a> 
</dt>
<dd>A User story epic is a narrative of stakeholders needs that can be narrowed down into smaller specific needs (user stories/requirements).</dd>

<dt>
	<a id="071e2f38a7caca8d25bc9448f43b4ae6">Validation framework</a> 
</dt>
<dd>Validation framework is a framework allowing good communication between users and developers, validation of developed products by users, and flexibility on the developer’s side to take change requests into account as soon as possible. The validation framework needs a description of the functionalities to be developed (user stories/requirements), the criteria that enable to verify that the developed component corresponds to the user needs (acceptance criteria), the definition of tasks for the developers (backlog) and the workflow.</dd>

<dt>
	<a id="d03c9a9e0263d53db0438e931b4cd50b">View service</a> 
</dt>
<dd>View service is a concept from <a href="https://inspire.ec.europa.eu/metadata-codelist/SpatialDataServiceType/view" target="_blank">INSPIRE</a> indicating a service type which presents a (pre)view of a dataset. Typically implemented as WMS or WMTS.</dd>

<dt>
	<a id="e99a3db053c4021fc0d54bb5bfa966fe">Web service</a> 
</dt>
<dd>Web service a service offered by a device to another device, communicating with each other via the Internet (source: <a href="https://en.wikipedia.org/wiki/Web_service" target="_blank">wikipedia</a>)</dd>

<dt>
	<a id="129cfa443c969983682416863b6c3939">WOSIS</a> 
</dt>
<dd><a href="https://www.isric.org/explore/wosis" target="_blank">WOSIS</a> is a global dataset, maintained at ISRIC, aiming to serve the user with a selection of standardised and ultimately harmonised soil profile data</dd>

<dt>
	<a id="49b2df2cd2f2211296e72454927f6f3a">WMS</a> 
</dt>
<dd>Web Map service (<a href="https://www.ogc.org/standard/wms/" target="_blank">WMS</a>) is a formalised protocol to exchange geospatial data represented as images</dd>

<dt>
	<a id="44c834e2130ff080f5d295fe73175a26">WFS</a> 
</dt>
<dd>Web Feature Service (<a href="https://www.ogc.org/standard/wfs/" target="_blank">WFS</a>) is a formalised protocol to exchange geospatial vector data</dd>

<dt>
	<a id="39a8915fd7a1890f2e77fff233b3669c">WCS</a> 
</dt>
<dd>Web Coverage Service (<a href="https://www.ogc.org/standard/wcs/" target="_blank">WCS</a>)  is a formalised protocol to exchange geospatial grid data</dd>

<dt>
	<a id="20b39502f12eea895e4e8a6333056bff">XSD</a> 
</dt>
<dd>XML Schema Definition (XSD) recommendation how to formally describe the elements in an Extensible Markup Language (XML) document (source: <a href="https://en.wikipedia.org/wiki/XML_Schema_(W3C)" target="_blank">wikipedia</a>)</dd>

</dl></section></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 - 2027 <a href="https://cordis.europa.eu/project/id/101112838">SoilWise Soil Mission Horizon Europe project No. 101112838</a>
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://www.linkedin.com/company/soilwise-project-eu/" target="_blank" rel="noopener" title="SoilWise on LinkedIn" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://www.facebook.com/profile.php?id=61551552876700" target="_blank" rel="noopener" title="SoilWise on Facebook" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256c0 120 82.7 220.8 194.2 248.5V334.2h-52.8V256h52.8v-33.7c0-87.1 39.4-127.5 125-127.5 16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287v175.9C413.8 494.8 512 386.9 512 256"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "/SoilWise-documentation/", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.path", "navigation.indexes", "content.action.edit", "content.footnote.tooltips"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../js/print-site.js"></script>
      
    
  </body>
</html>